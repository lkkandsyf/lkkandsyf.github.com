---
layout: post
category : Docker
tagline: "Supporting tagline"
tags : [ docker ]
---
{% include JB/setup %}

# Overview
{:.no_toc}

* dir
{:toc}

## Docker learn note

 + [Kumu-docker](http://blog.opskumu.com/docker.html)
 + [玩转Docker](http://blog.daocloud.io/how-to-master-docker-image/)


 + [阿里云加速](http://dev.aliyun.com/search.html)

---

## 安装Docker

Ubuntu:14.04中安装

	$sudo apt-get update
	$sudo apt-get install apt-transport-https ca-certificates
	$sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
	$echo "deb https://apt.dockerproject.org/repo ubuntu-trusty main" | sudo tee /etc/apt/sources.list.d/docker.list
	$sudo apt-get update
	$sudo apt-get install docker-engine
	$or curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - #来加速
	$sudo service docker start
	$sudo docker run hello-world

卸载Docker

	$sudo apt-get purge docker-engine
	$sudo apt-get autoremove --purge docker-engine
	$rm -rf /var/lib/docker


升级Docker

	$sudo apt-get update
	$sudo apt-get upgrade docker-engine

Centos:

[link](http://www.linuxidc.com/Linux/2014-07/104768.htm)


官网[https://docs.docker.com/engine/installation/linux/ubuntulinux/](https://docs.docker.com/engine/installation/linux/ubuntulinux/)


## 核心概念

Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。

Docker有三大核心概念：镜像（Image）、容器（Container）、仓库（Repository）。

## 拉取和推送

 + 拉取

首先，我们通过docker search image-name来搜索需要的镜像。然后通过docker pull image-name 来拉取镜像。

	sudo docker pull name[:TAG]
	sudo docker pull ubuntu:latest

 + 推送

 通过拉取基本的镜像之后，我们可以通过Dockfile或者commit来构建镜像，一般都会选择Dockfile来构建自己需要的镜像.

推送镜像的时候，我们需要登录dockerhub或者daocloud的网站进行注册，在需要推送的机器上使用命令登录

	docker login

查看信息

	cat .dockercfg

我们可以使用docker tag	来添加自己的名字。用docker images来查看镜像

	docker push daocloud-name/repo-name:latest

通过上面的命令就可以推送到dockerhub或者daocloud上，我们可以看到自己推送的tag，但是在推送之前必须把使用该镜像的容器stop，否则不能推送成功。

	docker push daocloud-name/repo-name:v1

---


## 制作镜像

两种方式制作镜像

 + docker commit命令

操作完之后，我们通过docker commit image-id daocloud-user-name/repo-name,通过docker images daocloud-user-name/repo-name来检查刚才创建的镜像

提交一个新的定制的镜像，docker commit -m "A new custom image" -a "author info" image-id daocloud-user-name/repo-name:context

-m:来指定新的镜像的提交信息

-a:列出该镜像的作者信息

daocloud-user-name/repo-name:指定了镜像的用户名和仓库名，并且为该镜像增加了一个context的标签。

可以使用docker inspect命令来查看新创建的镜像的详细信息.docker inspect daocloud-user-name/repo-name:context

从新提交的镜像运行一个新的容器，docker run -it daocloud-user-name/repo-name:context /bin/bash可以看出我们用了完整的标签来指定这个镜像。


 + 使用docker build命令和Dockfile文件(推荐)

简单demo:

	mkdir first-docker-file
	cd first-docker-file
	touch Dockfile

执行docker build命令时，Dockerfile中的所有指令都会被执行并且提交。并且在该命令成功结束后返回一个`新的镜像`。

	docker build -t="daocloud-user-name/repo-name" .

开始构建新的对象。如果没有指定任何tag，Docker将会自动为镜像设置一个latest标签


---

## 挂载本地目录

docker可以把一个宿主机上的`目录`挂载到`镜像里`

	docker run -it -v /home/user/Downloads:/usr/share ubuntu:14.04 /bin/bash

通过`-v`参数，冒号前为`宿主机目录`，必须为`绝对路径`，冒号后面为`镜像内挂载的目录的路径`

现在镜像内就可以访问共享宿主机里面的文件了。

默认挂载的路径`权限`为读写。如果指定为`只读`可以使用:ro

	docker run -it -v /home/user/Downloads:/usr/share:ro ubuntu:14.04 /bin/bash

docker还提供了一个`高级`的用法，叫做`数据卷`。

数据卷:“其实就是一个`正常的容器`，专门用来提供数据卷供`其他容器挂载`”,感觉像是由一个容器定义的一个`数据挂载信息`。其他的容器启动就可以直接挂载数据卷中定义的挂载信息。

	docker run -v /home/user/Downloads:/usr/share --name dataVol ubuntu:14.04 /bin/bash

创建一个普通的容器。用`--name`给它指定一个名(不指定的话，就会随机产生一个名字)

	docker ps -l

再创建一个新的容器，来使用这个数据卷。

	docker run -it --volumes-from dataVol ubuntu14.04 /bin/bash

--volumes-from用来指定要从哪个数据卷来挂载数据。同样都是在/usr/share目录下。

---

## 导入和导出镜像

可以使用docker save和docker load来存储镜像和载入镜像

保存镜像

	sudo docker images			#镜像列表
	sudo docker save -o xxxx.jar 要保存的镜像id		#保存镜像为文件
	sudo docker mirrorId > path/xxx.tar
	sudo docker save -o ubuntu.tar repo/ubuntu
	#完成之后用ls查看

加载镜像

	sudo docker load --input xxx.tar
	#or
	sudo docker load < xxx.tar

导出export和保存save的区别

 + export导出的镜像文件大小  小于 save保存的镜像
 + export 导出（import导入）是根据容器拿到的镜像，再导入时会丢失镜像所有的历史，所以无法进行回滚操作（docker tag <LAYER ID> <IMAGENAME>）；而save保存（load加载）的镜像，没有丢失镜像的历史，可以回滚到之前的层（layer）。（查看方式：docker images --tree）

注：导入加载进来觉得不合适可以使用 docker rm 容器ID 、 docker rmi 镜像ID 来删掉。

移除所有的容器和镜像：

	docker kill $(docker ps -q) ; docker rm $(docker ps -a -q) ; docker rmi $(docker images -q -a)

---


## 数据卷

	docker run -it --volumes-from dataVol ubuntu14.04 /bin/bash


## 网络配置

**端口映射**

从外部访问容器应用，可以通过-p/-P参数来指定端口映射。使用-P时，Docker会随机映射一个端口到容器内部开放的端口。-p会映射到指定的端口，支持的格式有

 + ip地址:主机端口:容器端口
 + ip地址::容器端口
 + 主机端口:容器端口

查看映射端口配置

	sudo  port containerid  port

容器有自己内部往来和IP地址

	sudo docker inspect containerid

exam:

	sudo docker run -it -p 127.0.0.1:4001:4000 jekyll/jekyll /bin/bash
	jekyll build
	jekyll serve

然后通过外部浏览器来访问localhost:4001

**容器互联**

容器的连接系统是除了端口映射另外一种可以与容器中应用进行交互的方式，它会在源和接受容器之间创建一个隧道，接受容器可以看到源容器的指定的信息

	sudo docker run -d -p --name blog jekyll/jekyll

容器的名字`必须是唯一的`，执行docker run 时，如果加上--rm参数，容器在终止的时候会立即被删除，但是不能与-d参数一起使用。

使用--link参数可以让容器直接建立安全的连接进行交互。

首先创建一个数据库的容器

	sudo dcoker run -d --name db training/postgres

创建web容器

	sudo docker run -d -p --name web --link db:db training/webapp python app.py

此时db容器和web容器相互联系。--link参数:--link name:alias,name是要连接的容器，alias是这个容器的别名，可以使用docker ps查看容器的信息，其中name列就能看出互联的状态

docker在两个`互联`容器直接建立一个`安全隧道`，不需要把它们的端口`映射到宿主主机上`，也可以避免端口的暴露。

Docker提供两种方式公开连接信息

 + 环境变量
 + 更新/etc/hosts文件

使用env命令可以看到容器的环境变量

---

## Docker cmd

[Dockfile-command](https://docs.docker.com/engine/reference/commandline/)

	docker login
	docker logout
	docker diff
	docker build
	docker commit
	docker create
	docker cp
	docker events
	docker export
	docker info
	docker kill
	docker pull
	docker run
	docker image
	docker tag
	docker inspect
	docker search
	docker rmi
	docker commit
	docker save
	docker load
	docker push
	docker logs
	docker ps
	docker restart
	docker attach
	docker exec
	docker top
	docker stop
	docker start
	docker port
	docker pause
	docker history
	docker version
	docker wait

---

## Dockerfile

我们可以是Dockfile文件`快速创建自定义的镜像`,一般分为`4个部分`

 + 基础镜像信息
 + 维护者信息
 + 镜像操作指令
 + 容器启动时的执行命令

**指令**

指令的一半格式是INSTRUCTION arguments

__FROM__

格式为:FROM <image> or FROM <image>:<tag>
Dockerfile文件第一行必须为FROM指令，如果在同一个Dockerfile创建多个镜像时，可以使用多个FROM指令(每个镜像一次)

__MAINTAINER__

指定维护者信息,格式为：MAINTAINER <name>

__RUN__

格式为RUN <command>或者RUN["executable","param1","param2"],前者将在shell终端运行命令，即/bin/sh -c,后者在使用exec执行。第二种方式可以指定`其他终端实现`，如:RUN ["/bin/bash","-c","echo hello"],RUN命令将在当前镜像基础上执行执行命令,并提交为新的镜像，当命令较长时，可以使用\来换行。

__CMD__

指定启动容器时执行的命令，每个Dockerfile`只能有一条CMD命令`，如果指定了多个命令，只有`最后一条命令执行`,该命令支持三种格式：

 +  CMD ["executable","param1","param2"]:使用exec执行
 +  CMD command param1 param2:在/bin/bash中执行，提供给需要交互的应用
 +  CMD ["param1","param2"]:提供给ENTRYPOINT默认参数

如果在其中容器中指定了运行的命令，就会覆盖掉CMD命令

__EXPOSE__

告诉Docker服务器容器需要暴露的端口号，`供互联系统使用`

格式:EXPOSE <port> [<port>...]

在容器启动时，需要通过-P让Docker主机自动分配一个端口转发到指定的端口，使用-p则可以具体指定哪个本地端口会映射过来。

__ENV__

指定环境变量，会被后面RUN指令使用，并在容器运行时保持

格式:ENV <key> <value>

__ADD__

该命令向容器中复制文件

格式:ADD <src> <dst>
指定的src会被复制到dst，src可以是Dockerfile所在目录的一个`相对路径(文件或者目录)，也可以是一个URL，还可以是一个tar包，--会自动解包为一个目录`

__COPY__

格式:COPY <src> <dst>

复制主机的<src>(Dockerfile所在的目录的相对路径，文件或目录)为容器<dst>,目标路径不存在时会自动创建。

__ENTRYPOINT__

配置容器启动后执行的命令，并且不尅被docker run命令提供过的参数覆盖

格式:

 + ENTRYPOINT ["executable","param1","param2"]
 + ENTRYPOINT command param1 param2:shell中执行

 同样的，每个Dockerfile中`只能有一个该指令，指定多个时，只有最后一个生效`

__VOLUME__

创建一个可以从本地主机或其他容器挂载的挂载点，一般是`用来存放数据库和需要保持的数据等`。

__USER__

指定运行容器时用户名或UID，后续的RUN也会指定为该用户

格式: USER daemon

__WORKDIR__

为后续的RUN，CMD，ENTRYPOINT执行配置工作路径

格式:WORKDIR /path/to/workdir

可以使用多个该指令，后续指令如果是相对路径，则会`基于之前的命令执行路径`

	workdir /A
	workdir B
	RUN X

则最终的路径为:/A/B.

__ONBUILD__

配置当前所创建的镜像作为其他新创建镜像的基础镜像，所执行的操作指令。

格式:ONBUILD [INSTRUCTION]

比如:

	ONBUILD ADD . /app/src
	ONBUILD RUN /usr/local --dir /app/src
	....

如果基于以上继续创建新镜像时，新的Dockerfile中使用的FROM指定以上为基础镜像，会自动执行ONBUILD指令内容，等价后面添加两条指令。

__LABLE__

__STOPSIGNAL__

__ONBUILD__

**创建镜像**

编写好Dockerfile，可以通过docker build来创建镜像

基本格式:docker buidl 选项 路径

该命令会自动读取指定路径(包含子目录)的Dockerfile，并将路径下的所有内容发送到docker服务器，创建镜像

	sudo docker build -t image_name /src/dockerfile_path

**Dockerfile**

```
# Dockerfile for ELK stack
# Elasticsearch 5.0.0, Logstash 5.0.0, Kibana 5.0.0

# Build with:
# docker build -t <repo-user>/elk .

# Run with:
# docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -it --name elk <repo-user>/elk

FROM phusion/baseimage
MAINTAINER Sebastien Pujadas http://pujadas.net
ENV REFRESHED_AT 2016-10-30

###############################################################################
#                                INSTALLATION
###############################################################################

### install prerequisites (cURL, gosu)

ENV GOSU_VERSION 1.8

RUN set -x \
 && apt-get update -qq \
 && apt-get install -qqy --no-install-recommends ca-certificates curl \
 && rm -rf /var/lib/apt/lists/* \
 && curl -L -o /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture)" \
 && curl -L -o /usr/local/bin/gosu.asc "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture).asc" \
 && export GNUPGHOME="$(mktemp -d)" \
 && gpg --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4 \
 && gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu \
 && rm -r "$GNUPGHOME" /usr/local/bin/gosu.asc \
 && chmod +x /usr/local/bin/gosu \
 && gosu nobody true \
 && apt-get clean \
 && set +x


### install Elasticsearch

ENV ES_VERSION 5.0.0
ENV ES_GID 991
ENV ES_UID 991

RUN curl https://artifacts.elastic.co/GPG-KEY-elasticsearch | apt-key add -
RUN apt-get install apt-transport-https
RUN echo deb https://artifacts.elastic.co/packages/5.x/apt stable main > /etc/apt/sources.list.d/elasticsearch-5.x.list

RUN groupadd -r elasticsearch -g ${ES_GID} \
 && useradd -r -s /usr/sbin/nologin -M -c "Elasticsearch service user" -u ${ES_UID} -g elasticsearch elasticsearch \
 && apt-get update -qq \
 && apt-get install -qqy \
		elasticsearch \
		openjdk-8-jdk \
 && apt-get clean


### install Logstash

ENV LOGSTASH_VERSION 5.0.0
ENV LOGSTASH_HOME /opt/logstash
ENV LOGSTASH_PACKAGE logstash-${LOGSTASH_VERSION}.tar.gz
ENV LOGSTASH_GID 992
ENV LOGSTASH_UID 992

RUN mkdir ${LOGSTASH_HOME} \
 && curl -O https://artifacts.elastic.co/downloads/logstash/${LOGSTASH_PACKAGE} \
 && tar xzf ${LOGSTASH_PACKAGE} -C ${LOGSTASH_HOME} --strip-components=1 \
 && rm -f ${LOGSTASH_PACKAGE} \
 && groupadd -r logstash -g ${LOGSTASH_GID} \
 && useradd -r -s /usr/sbin/nologin -d ${LOGSTASH_HOME} -c "Logstash service user" -u ${LOGSTASH_UID} -g logstash logstash \
 && mkdir -p /var/log/logstash /etc/logstash/conf.d \
 && chown -R logstash:logstash ${LOGSTASH_HOME} /var/log/logstash

ADD ./logstash-init /etc/init.d/logstash
RUN sed -i -e 's#^LS_HOME=$#LS_HOME='$LOGSTASH_HOME'#' /etc/init.d/logstash \
 && chmod +x /etc/init.d/logstash


### install Kibana

ENV KIBANA_VERSION 5.0.0
ENV KIBANA_HOME /opt/kibana
ENV KIBANA_PACKAGE kibana-${KIBANA_VERSION}-linux-x86_64.tar.gz
ENV KIBANA_GID 993
ENV KIBANA_UID 993

RUN mkdir ${KIBANA_HOME} \
 && curl -O https://artifacts.elastic.co/downloads/kibana/${KIBANA_PACKAGE} \
 && tar xzf ${KIBANA_PACKAGE} -C ${KIBANA_HOME} --strip-components=1 \
 && rm -f ${KIBANA_PACKAGE} \
 && groupadd -r kibana -g ${KIBANA_GID} \
 && useradd -r -s /usr/sbin/nologin -d ${KIBANA_HOME} -c "Kibana service user" -u ${KIBANA_UID} -g kibana kibana \
 && mkdir -p /var/log/kibana \
 && chown -R kibana:kibana ${KIBANA_HOME} /var/log/kibana

ADD ./kibana-init /etc/init.d/kibana
ADD ./kibana.yml ${KIBANA_HOME}/config/kibana.yml

RUN sed -i -e 's#^KIBANA_HOME=$#KIBANA_HOME='$KIBANA_HOME'#' /etc/init.d/kibana \
 && chmod +x /etc/init.d/kibana


###############################################################################
#                               CONFIGURATION
###############################################################################

### configure Elasticsearch

ADD ./elasticsearch.yml /etc/elasticsearch/elasticsearch.yml


### configure Logstash

# certs/keys for Beats and Lumberjack input
RUN mkdir -p /etc/pki/tls/certs && mkdir /etc/pki/tls/private
ADD ./logstash-beats.crt /etc/pki/tls/certs/logstash-beats.crt
ADD ./logstash-beats.key /etc/pki/tls/private/logstash-beats.key

# filters
ADD ./02-beats-input.conf /etc/logstash/conf.d/02-beats-input.conf
ADD ./10-syslog.conf /etc/logstash/conf.d/10-syslog.conf
ADD ./11-nginx.conf /etc/logstash/conf.d/11-nginx.conf
ADD ./30-output.conf /etc/logstash/conf.d/30-output.conf

# patterns
ADD ./nginx.pattern ${LOGSTASH_HOME}/patterns/nginx
RUN chown -R logstash:logstash ${LOGSTASH_HOME}/patterns


### configure logrotate

ADD ./elasticsearch-logrotate /etc/logrotate.d/elasticsearch
ADD ./logstash-logrotate /etc/logrotate.d/logstash
ADD ./kibana-logrotate /etc/logrotate.d/kibana
RUN chmod 644 /etc/logrotate.d/elasticsearch \
 && chmod 644 /etc/logrotate.d/logstash \
 && chmod 644 /etc/logrotate.d/kibana


###############################################################################
#                                   START
###############################################################################

ADD ./start.sh /usr/local/bin/start.sh
RUN chmod +x /usr/local/bin/start.sh

EXPOSE 5601 9200 9300 5044
VOLUME /var/lib/elasticsearch

CMD [ "/usr/local/bin/start.sh" ]
```

---

## Problem

 + Repository busybox already being pulled by another client. Waiting.

	restart the docker : service docker restart

