---
layout: post
category : Big-data
tagline: "Supporting tagline"
tags: Phoenix
  -
title: 'sql engine base on Hbase Phoenix'
---
Phoenix通过jdbc来连接hbase，类似的操作关系型数据库,当然也损失了一部分的性能.但需要进一步的优化。

---
通过JDBC API实现了大部分的java.sql接口，包括元数据API
DDL支持：通过CREATE TABLE、DROP TABLE及ALTER TABLE来添加/删除
DML支持：用于逐行插入的UPSERT VALUES,用于相同或不同表之间大量数据传输的UPSERT SELECT,用于删除行的DELETE
事务支持：通过客户端的批处理实现的有限的事务支持(beta测试中)
二级索引支持：
遵循ANSI SQL标准

[http://phoenix.apache.org](http://phoenix.apache.org)
<!--more-->

## config

 在Hbase的基础上,下载Phoenix的tar包，把hbase的conf下的hbase-site.xml中的内容和phoenix下bin/的hbase-site.xml进行合并，然后分别放到两个对应的目录下
 ```C
 $HBASE_HOME/conf/hbase-site.xml
 $PHOENIX_HOME/bin/hbase-site.xml
 ```
 接下来把phoenix的相关jar包拷贝到hbase的lib下
 ```C
 cp $PHOENIX_HOME/phoenix-4.14.1-HBase-1.3-client.jar $HBASE_HOME/lib/
 cp $PHOENIX_HOME/phoenix-4.14.1-HBase-1.3-server.jar $HBASE_HOME/lib/
 cp $PHOENIX_HOME/phoenix-core-4.14.1-HBase-1.3.jar  $HBASE_HOME/Lib/
 ```
 重启hbase,通过$PHOENIX\_HOME/bin/sqlline.py `master`:2181,这个`master一定是zk的地址`，否则会连不上,通过!list来列出当前的表

Phoenix环境下Hbase `table名大小写敏感`，小写命名必须加上双引号，在Phoenix默认配置下，如果查询时间过长(超过一分钟或者更多)，就会抛出相应的TimeoutException.可通过修改参数
```c
<property>
  <name>phoenix.query.timeoutMs</name>
  <value>3600000</value>
</property>

<property>
  <name>hbase.rpc.timeout</name>
  <value>3600000</value>
</property>
```
实际应用中不建议设置太长,10分钟

Phoenix二级索引表与源数据表保持同步的前提

源数据表的增、删、改操作必须通过Phoenix命令行或者客户端，才能保证二级索引表与源表保持同步。Phoenix提供的Bulk Loading同样也能保证二级索引表与源数据表保持同步。

测试数据：
```c
./sqlline.py master:2181 ../examples/STOCK_SYMBOL.sql
Setting property: [incremental, false]
Setting property: [isolation, TRANSACTION_READ_COMMITTED]
Setting property: [run, ../examples/STOCK_SYMBOL.sql]
issuing: !connect jdbc:phoenix:master:2181 none none org.apache.phoenix.jdbc.PhoenixDriver
Connecting to jdbc:phoenix:master:2181
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/big-data/phoenix/phoenix-4.14.1-HBase-1.3-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/big-data/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
18/12/17 09:29:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Connected to: Phoenix (version 4.14)
Driver: PhoenixEmbeddedDriver (version 4.14)
Autocommit status: true
Transaction
lation: TRANSACTION_READ_COMMITTED
Building list of tables and columns for tab-completion (set fastconnect to true to skip)...
135/135 (100%) Done
Done
1/4          CREATE TABLE IF NOT EXISTS STOCK_SYMBOL (SYMBOL VARCHAR NOT NULL PRIMARY KEY, COMPANY VARCHAR);
No rows affected (2.388 seconds)
2/4          UPSERT INTO STOCK_SYMBOL VALUES ('CRM','SalesForce.com');
1 row affected (0.024 seconds)
3/4          SELECT * FROM STOCK_SYMBOL;
+---------+-----------------+
| SYMBOL  |     COMPANY     |
+---------+-----------------+
| CRM     | SalesForce.com  |
+---------+-----------------+
1 row selected (0.051 seconds)
4/4
Closing: org.apache.phoenix.jdbc.PhoenixConnection
sqlline version 1.2.0

```
加载数据并查询
```C
WEB_STAT.sql创建表
WEB_STAT.csv数据
WEB_STAT_QUERY.sql查询sql
./psql.py master:2181 ../examples/WEB_STAT.sql ../examples/WEB_STAT.csv ../examples/WEB_STAT_QUERIES.sql
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/big-data/phoenix/phoenix-4.14.1-HBase-1.3-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/big-data/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
18/12/17 09:39:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
no rows upserted
Time: 2.417 sec(s)

csv columns from database.
CSV Upsert complete. 39 rows upserted
Time: 0.051 sec(s)

DOMAIN                                                          AVERAGE_CPU_USAGE                         AVERAGE_DB_USAGE
---------------------------------------- ---------------------------------------- ----------------------------------------
Salesforce.com                                                            260.727                                  257.636
Google.com                                                                212.875                                   213.75
Apple.com                                                                 114.111                                  119.556
Time: 0.018 sec(s)

DAY                                              TOTAL_CPU_USAGE                            MIN_CPU_USAGE                            MAX_CPU_USAGE
----------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
2013-01-01 00:00:00.000                                       35                                       35                                       35
2013-01-02 00:00:00.000                                      150                                       25                                      125
2013-01-03 00:00:00.000                                       88                                       88                                       88
2013-01-04 00:00:00.000                                       26                                        3                                       23
2013-01-05 00:00:00.000                                      550                                       75                                      475
2013-01-06 00:00:00.000                                       12                                       12                                       12
2013-01-08 00:00:00.000                                      345                                      345                                      345
2013-01-09 00:00:00.000                                      390                                       35                                      355
2013-01-10 00:00:00.000                                      345                                      345                                      345
2013-01-11 00:00:00.000                                      335                                      335                                      335
2013-01-12 00:00:00.000                                        5                                        5                                        5
2013-01-13 00:00:00.000                                      355                                      355                                      355
2013-01-14 00:00:00.000                                        5                                        5                                        5
2013-01-15 00:00:00.000                                      720                                       65                                      655
2013-01-16 00:00:00.000                                      785                                      785                                      785
2013-01-17 00:00:00.000                                     1590                                      355                                     1235
Time: 0.014 sec(s)

HO                    TOTAL_ACTIVE_VISITORS
-- ----------------------------------------
EU                                      150
NA                                        1
Time: 0.009 sec(s)
```

Phoenix Buld Loading `导入大批量数据`

 + psql load data 文件名后缀必须是`csv`,要不然可能会出错。

 ```c
 ./psql.py -help
  Examples:
  psql my_ddl.sql
  psql localhost my_ddl.sql
  psql localhost my_ddl.sql my_table.csv
  psql -t MY_TABLE my_cluster:1825 my_table2012-Q3.csv
  psql -t MY_TABLE -h COL1,COL2,COL3 my_cluster:1825 my_table2012-Q3.csv
  psql -t MY_TABLE -h COL1,COL2,COL3 -d : my_cluster:1825 my_table2012-Q3.csv
 ```
 使用psql.py来导入大批量数据在表名为`小写的时候无法识别`，会抛TableNotFoundException异常
 + mapreduce

 ```c
 ```

 python:
 ```c
 /opt/big-data/spark/bin/pyspark --jars /opt/big-data/phoenix/phoenix-4.14.1-HBase-1.3-client.jar --conf spark.executor.extraClassPath=/opt/big-data/phoenix/phoenix-4.14.1-HBase-1.3-client.jar

 ```
 [https://phoenix.apache.org/phoenix_spark.html](https://phoenix.apache.org/phoenix_spark.html)

 Phoenix表的管理维护

 + 通过Phoenix创建的表必须指定primary key（对应hbase的rowkey），列最好明确指定列族名称（除了primary key不用指定，其他列建议指定），列类型最好都指定为varchar。

 + 通过Phoenix创建的表如果要删除，不要在HBase Shell或者使用HBase客户端API等删除，必须在Phoenix里面删除，否则会出现删除后在Phoenix还能看到该删除掉的表，但是在该表上的操作都会抛异常。并且只有在Phoenix指定删除才能删除对应的、可能存在的二级索引表。

`note`

HBase版本需要与集群的HBase版本对应，否则可能报找不到对应方法的异常。

### Phoenix视图映射Hbase中的表
 1. Hbase 创建表
 ```C
 hbase shell
 create 'TEST','INFO'
 ```
 2. 添加数据
 ```C
 put 'TEST', 'aaaaaaaaa1', 'INFO:NAME', 'phoenix'
 put 'TEST', 'aaaaaaaaa2', 'INFO:AGE', '5'
 ```
 `note`:
 ```C
 这里HBase表名、列簇、列修饰符为什么全部都是大写的呢？
 因为在Phoenix里写着方便啊，Phoenix里的表名要与HBase的表名保持一致
 `Phoenix不管你输入的是大写还是小写都默认把它转成大写的，如果要小写的话必须加上引号`
 ```
 3. 查看数据
 ```C
 scan 'TEST'
 ```
 如果数据很大，通过LIMIT 来限制scan 'TEST', {LIMIT=>5},只显示5条数据
 4. 映射转换
 ```C
 通过sqlline.py进去Phoenix终端
 ```
 5. 创建视图
 ```C
 create view test (pk varchar primary key,info.name varchar,info.age varchar) as select * from test;
 !tables
 !describe user
 ```
 针对不同的数据类型int 需要用unsiged
 6. 查询数据
 ```C
 select * from test limit 5;
 ```

## 原理

架构:

![phoenix](http://lkkandsyf.github.com/pictures/phoenix-framework.png)

其中黄色部分是HBase的组件，蓝色部分是Phoenix，我们可以看出Phoenix跟HBase是紧密结合的。Phoenix首先要能通过SQL暴露HBase的能力，然后再通过一系列功能和特性增强HBase能力，并且还要做到足够易用



## 常用语法

type:[http://phoenix.apache.org/language/datatypes.html](http://phoenix.apache.org/language/datatypes.html)

 + bigint
 + varchar
 +
 +
 +
 +
 +
 +
 +
 +
 +
 +

0.查询
select

1.插入或更新
upsert

2.删除
delete

3.排序
order by

4.模糊匹配
like

5.聚合函数
sum
count
avg
having
distinct
or
limit
group by
union all
left join

6.视图
```c
# delete view
drop view if exists view_syf cascade;

# create table view,就和原表是一样的数据
create view view_syf as select * from syf;
#create view add family
create view view_syf
(
	id bigint primary key,
	"F1".syf bigint -- F1 is column family
) as select * form syf;
```

7.索引

```c
# delete index
drop index if exists syf_index on syf;

#create index
create index syf_index on syf (syf.id);
```
二级索引设计比较粗糙
```C
create index index_name tablename(idx_field);
select OtherField from tablename where idx_field = '';
以为这样就可以使用索引了，其实不然，必须要这样操作

create index index_name tablename(idx_field) include(OtherField);
```
因为二级索引创建了一个新的索引表，没有INICLUDE时，索引表中的value为空，上述查询将不会利用索引表，而是Full Scan主表。INCLUDE时，会将OtherField字段写入索引表的value中，上述查询将会利用索引表进行Range Sacn。

使用索引 SELECT * FROM TAB\_NAME t1 INNER ON ( SELECT ROW\_KEY FROM TABLE\_NAME WHERR IDX\_FIELD='' ) t2 ON t1.ROW\_KEY = t2.ROW\_KEY; 其实就是先利用索引表查到主键，再根据主键查询定位其所在记录。

[http://phoenix.apache.org/secondary_indexing.html](http://phoenix.apache.org/secondary_indexing.html)

8.序列

结合序列实现自增主键
```c
create sequence my_sequence;
upsert into tablename(fields) values(next value for my_sequence,'name')
```

phoenix grammar

[http://phoenix.apache.org/language/index.html](http://phoenix.apache.org/language/index.html)

## example

```c
select * from test order by id desc,name desc;

```

## 热点

通过加盐的方式来避免,加盐的过程本质上是对原有的主键加上一个字节的前缀，如下面公式所示：
```c
new_row_key = (++index % BUCKETS_NUMBER) + original_key
```
其中，BUCKETS\_NUMBER为桶的个数。主键的分布决定了数据的分布，把主键打散也就意味着数据打散。具体使用时，一般建议`桶的数目等于RegionServer的数目`。


## Hbase 二级索引方案


 + 使用开源的hbase-indexer，是借助于hbase的WAL实现，不会影响hbase性能
 + 基于ES自己实现，利用habse的协处理器实现，会影响hbase性能,关键注意点：因为数据是存在Hbase中，ES充当的是索引角色，所以在创建ES的mapping时，应指定\_source为enabled:false。关闭存储原始文档。


## JDBC

Phoenix提供了轻便的客户端模式

Server:python $PHOENIX\_HOME/bin/queryserver start

Client:python $PHOENIX\_HOME/bin/sqlline-thin.py http://localhost:8765


[http://phoenix.apache.org/server.html](http://phoenix.apache.org/server.html)

[http://calcite.apache.org/avatica/docs/json_reference.html](http://calcite.apache.org/avatica/docs/json_reference.html)

## reference

hbase-phoenix版本兼容

[https://phoenix.apache.org/download.html](https://phoenix.apache.org/download.html)

```C
Version	Release		Date

5.0.0-HBase-2.0		04/jul/2018

4.14.0-HBase-1.4	09/jun/2018

4.14.0-HBase-1.3	09/jun/2018

4.14.0-HBase-1.2	09/jun/2018
```

