---
layout: post
category : ELK
tagline: "Supporting tagline"
tags : []
---
ELK 分析
---
<!--more-->
---

## elk 开源实时日志分析平台搭建 ubuntu

需要JDK依赖包 java -version

{% highlight C linenos %}
# mkdir /usr/local/java
# tar -zxf jdk-8u45-linux-x64.tar.gz -C /usr/local/java/

setup env
# tail -3 ~/.bash_profile
export JAVA_HOME=/usr/local/java/jdk1.8.0_45
export PATH=$PATH:$JAVA_HOME/bin
exportCLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH
{% endhighlight %}
 + 下载文件 Elasticsearch Logstash Kibana [link](https://www.elastic.co/downloads)

Elasticsearch:搜索和实时分析数据 open source

```c
axel -n 10 https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.4.1/elasticsearch-2.4.1.tar.gz

`or`

curl -L -O https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-2.4.1.tar.gz
```
Logstash:收集，丰富，传输数据 open source
下载对应的包

Kibana:可视化数据平台 open source
下载对应的包

 + 安装

为了统一化，把解压之后的文件的版本号都去掉。

## 安装Logstash

只需要把它解压到对应的`	目录`即可,例如:/usr/local/
{% highlight C linenos %}
tar -zxf logstash.tar.gz -C /usr/local/
or
tar xf logstash.tar.gz
sudo cp -R logstash /usr/local/
{% endhighlight %}
安装完成之后，通过如下命令来测试

{% highlight C linenos %}
/usr/local/logstash/bin/logstash -e 'input { stdin {  }  } output { stdout {}  }'
Settings: Default pipeline workers: 8
Pipeline main started
hello world
2016-10-16T12:29:45.603Z lkk hello world
{% endhighlight %}
我们可以看到，`我们输入什么内容logstash按照某种格式输出`,其中-e参数参数允许logstash直接通过命令行接受设置。可以快速的帮助我们反复的`测试配置是否正确而不用写配置文件`。使用CTRL-C命令可以退出之前运行的logstash。

使用-e参数在命令行中指定配置是很常用的方式，不过如果`需要配置更多设置则需要很长的内容`。这种情况，我们首先`创建一个简单的配置文件`，并且指定logstash使用这个配置文件。例如：在logstash安装目录下创建一个“基本配置”测试文件logstash-test.conf，文件内容如下：
{% highlight C linenos %}
cat logstash-test.conf
input { stdin {  }  }
output {
	   stdout { codec=> rubydebug  }
}
{% endhighlight %}

Logstash使用input和output定义收集日志时的输入和输出的相关配置，本例中input定义了一个叫"stdin"的input，output定义一个叫"stdout"的output。无论我们输入什么字符，Logstash都会按照某种格式来返回我们输入的字符，其中output被定义为"stdout"并使用了codec参数来指定logstash输出格式。

使用logstash的-f参数来读取配置文件，执行如下开始进行测试：

{% highlight C linenos %}
/logstash/bin/logstash agent -f logstash-test.conf
Settings: Default pipeline workers: 8
Pipeline main started
// 这里输入日志，下面就会有记录
hello world elk i am lkk
Settings: Default pipeline workers: 8
Pipeline main started
hello world elk i am lkk
{
	"message" => "hello world elk i am lkk",
	"@version" => "1",
	"@timestamp" => "2016-10-16T12:41:16.830Z",
	"host" => "lkk"
}
{% endhighlight %}

## 安装Elasticsearch
只需要把它解压到对应的`	目录`即可,例如:/usr/local/
{% highlight C linenos %}
tar -zxf logstash.tar.gz -C /usr/local/
or
tar xf logstash.tar.gz
sudo cp -R logstash /usr/local/
{% endhighlight %}

启动Elasticsearch
{% highlight C linenos %}
/usr/local/elasticsearch-1.6.0/bin/elasticsearch
{% endhighlight %}

安装elasticsearch插件Elasticsearch-kop插件可以查询Elasticsearch中的数据，安装Elasticsearch-kop，只要在安装elasticsearch目录下执行一下命令

{% highlight C linenos %}
cd /usr/local/elasticsearch/bin
./plugin -h查看帮助手册
./plugin install lmenezes/elasticsearch-kopf
{% endhighlight %}
安装完成之后，在plugin目录下可以看到kopf
{% highlight C linenos %}
ls plugin/
kopf
http://localhost:9200/_plugin/kopf :access data web
{% endhighlight %}


**ES plugins**

[office plugins](https://www.elastic.co/guide/en/elasticsearch/plugins/2.4/index.html)

[chinese plugins introducation](http://www.searchtech.pro/elasticsearch-plugins)

ES+Logstash+Kibana
[cnblog course](http://www.cnblogs.com/xing901022/p/4704319.html)

1.elasticsearch-head plugin,elasticsearch-head是一个elasticsearch的集群管理工具，它是完全由html5编写的独立网页程序，你可以通过插件把它集成到es。

```c
./plugin install mobz/elasticsearch-head
#access by the web
#http://localhost:9200/_plugin/head/
#粗线绿框表示主分片，细线绿框为备份分片。
```
2.bigdesk是elasticsearch的一个集群监控工具，可以通过它来查看es集群的各种状态，如：cpu、内存使用情况，索引数据、搜索情况，http连接数等。

[github](https://github.com/hlstudio/bigdesk)

```c
./plugin install lukas-vlcek/bigdesk
#more better
./plugin install hlstudio/bigdesk
#access by the web
#http://127.0.0.1:9200/_plugin/bigdesk
```

3.ik分词插件

[office](https://github.com/medcl/elasticsearch-analysis-ik)

**Logstash plugin**

[office plugins](https://www.elastic.co/guide/en/logstash/current/input-plugins.html)


**Kibana plugins**

[office plugins](https://www.elastic.co/guide/en/kibana/master/kibana-plugins.html)


如果使用远程连接的Linux的方式并且想在`后台`运行elasticsearch执行如下命令
{% highlight C linenos %}
nohup /usr/local/elasticsearch/bin/elasticsearch >nohup &
{% endhighlight %}

确认elasticsearch的9200端口已经监听，说明elasticsarch 已经运行
{% highlight C linenos %}
netstat -anp |grep :9200
tcp        0      0 :::9200                     :::*             LISTEN    3362/java
{% endhighlight %}

接下来我们在logstash安装目录下创建一个用于测试logstash使用elasticsearch作为logstash的后端的测试文件logstash-es-simple.conf，该文件中定义了stdout和elasticsearch作为output，这样的“多重输出”即保证输出结果显示到屏幕上，同时也输出到elastisearch中
{% highlight C linenos %}
# cat logstash-es-simple.conf
input { stdin {  }  }
output {
	elasticsearch {hosts => "localhost" }
	stdout { codec=> rubydebug  }
}
{% endhighlight %}

<font color="red">note</font>在logstash>2*的版本中,elasticsearch的参数名应为hosts,如果设置为host会出现configerror,`此处可以配置多个数据源`

{% highlight C linenos %}
/usr/local/logstash/bin/logstash agent -f logstash-es-simple.conf
// 输入内容
lkk learn elk
{
	"message" => "lkk learn elk",
	"@version" => "1",
	"@timestamp" => "2016-10-16T13:16:05.348Z",
	"host" => "lkk"
}
{% endhighlight %}

我们可以使用curl命令来发送请求查看ES是否接受到了数据
{% highlight C linenos %}
curl 'http://localhost:9200/_search?pretty'
{
	"_index" : "logstash-2016.10.16",
	"_type" : "logs",
	"_id" : "AVfNopHnP1IlSqIixQY1",
	"_score" : 1.0,
	"_source" : {
		"message" : "lkk learn elk",
		"@version" : "1",
		"@timestamp" : "2016-10-16T13:16:05.348Z",
		"host" : "lkk"
	}

}
{% endhighlight %}

查看elastricsearch是否同步数据成功
{% highlight C linenos %}
curl 'http://localhost:9200/_cat/indices?v'
health status index               pri rep docs.count docs.deleted store.size pri.store.size
yellow open   logstash-2016.10.16   5   1          3            0     12.6kb         12.6kb
{% endhighlight %}
说明数据成功导入，而且在`设置定时任务的情况下`，index的索引的容量不断增加.

看来这个主要的任务的`就是如何设置配置文件`

**插件**

安装logstash-input-jdbc的logstash的插件。用来进行mysql,oracle等的数据同步

{% highlight C linenos %}
/bin/plugin install logstash-input-jdbc  // 等待完成
{% endhighlight %}

demo-logstash
{% highlight C linenos %}
cat logstash-mysql.conf
input {
  jdbc {
    jdbc_driver_library => "/usr/local/logstash-2.4.0/mysql-connector-java-5.1.39.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://192.168.****:3306/******?characterEncoding=UTF-8&useSSL=false"
    jdbc_user => "*****"
    jdbc_password => "*********"
    statement => "SELECT * FROM news limit 0,1"
    jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    schedule => "* * * * *"
  }
}

filter {
   json {
        source => "message"
        remove_field => ["message"]
    }
}

output {
  stdout {
    codec => rubydebug
  }
  elasticsearch {
    hosts => "localhost"
    index => "myindex"
  }
}

{% endhighlight %}
启动logstash

/usr/local/logstash/bin/logstash -f logstash-mysql.conf

这个进程会一直执行下去,因为设置的schedule=>""(每分钟执行一次)，如果想结束，直接kill。


## 安装Kibana

只需要把它解压到对应的`	目录`即可,例如:/usr/local/
{% highlight C linenos %}
tar -zxf kibana.tar.gz -C /usr/local/
or
tar xf kibana.tar.gz
sudo cp -R kibana /usr/local/

start kibana
/usr/local/kibana/bin/kibana
{% endhighlight %}
安装完成之后，通过如下命令来测试,在web页面输入http://localhost:5601,登录后，配置一个索引，默认，Kibana的数据指向Elasticsearch，使用默认的logstash-*的索引名称，并且是基于时间的，点击"create"即可。
接下来，点击"discover"，可以搜索和浏览Elasticsearch中的数据，默认是`搜索的最近15分钟`的数据，可以自定义时间。


练习:索引本地日志系统,通过平台实时查看

## elk-docker

使用指南

[sebp/elk:document](http://elk-docker.readthedocs.io/)

[Dockerfile](https://hub.docker.com/r/sebp/elk/~/dockerfile/)



