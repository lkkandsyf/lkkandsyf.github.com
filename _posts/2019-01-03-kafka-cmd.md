---
layout: post
category: Kafka
tagline: "Supporting tagline"
tags:
  -
title: 'Kafka命令大全'
---

---


<!--more-->

## 单节点

###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###




## 分布式集群

启动zk,kakfa集群,三个节点
```c
netstat -ntlp |grep 9092
netstat -ntlp |grep 2181
```
验证是否启动成功

### 创建topic

```c
#$KAFKA_HOME/bin/kafka-topics.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 3 --partitions 6 --topic test
#$KAFKA_HOME/bin/kafka-topics.sh --describe  --zookeeper master:2181,slave1:2181,slave2:2181  --topic test
Topic:test	PartitionCount:6	ReplicationFactor:3	Configs:
	Topic: test	Partition: 0	Leader: 3	Replicas: 1,2,3	Isr: 3,1,2
	Topic: test	Partition: 1	Leader: 3	Replicas: 2,3,1	Isr: 3,1,2
	Topic: test	Partition: 2	Leader: 3	Replicas: 3,1,2	Isr: 3,1,2
	Topic: test	Partition: 3	Leader: 3	Replicas: 1,3,2	Isr: 3,1,2
	Topic: test	Partition: 4	Leader: 3	Replicas: 2,1,3	Isr: 3,1,2
	Topic: test	Partition: 5	Leader: 3	Replicas: 3,2,1	Isr: 3,1,2
```
Partition:

Leader:

Replicas:

Isr:

###得到topic的offset

```C
/opt/nsfocus/espc/deps/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic topic_name
```

### 动态增加分区

Kafka提供了kafka-reassign-partitions.sh这个脚本，可以动态扩容,运行时需要指定一个json文件:
```c
{
    "version": 1,
    "partitions": [
        {
            "topic": "test",
            "partition": 0,
            "replicas": [
                1,
                2,
                3
            ]
        },
        {
            "topic": "test",
            "partition": 1,
            "replicas": [
                1,
                2,
                3
            ]
        },
        {
            "topic": "test",
            "partition": 2,
            "replicas": [
                1,
                2,
                3
            ]
        },.....
    ]
}
```
生成这个文件，对于所有的topic，也可以自己指定,首先列出当前的的 topic
```c
$KAFKA_HOME/bin/kafka-topics.sh --list --zookeeper localhost:2181
$KAFKA_HOME/bin/kafka-topics.sh --list --zookeeper localhost:2181 > topics
```
除了`__consumer_offsets`,这是一个特殊的topic，记录着所有topic的offset,默认是三个副本，分区通过配置得到和基本的topic的分区是一样的,通过py脚本读取topics的内容，就可以生成上面的json文件
```c


```



`note`:Kafka Producer能否`动态感知`Topic分区的变化,当然是可以的啦,经过的时间间隔就是
```c
metadata.max.age.ms==300000
```
决定的,默认是5分钟 Kafka.2.10-0.10.2.1配置参数[http://kafka.apache.org/0102/documentation.html#producerconfigs](http://kafka.apache.org/0102/documentation.html#producerconfigs)

[https://www.iteblog.com/archives/1618.html](https://www.iteblog.com/archives/1618.html)

### 动态增加副本




###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
###
