<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>liangkangkang's Blog</title>
 <link href="" rel="self"/>
 <link href=""/>
 <updated>2019-11-30T19:10:00+08:00</updated>
 <id></id>
 <author>
   <name>liangkangkang</name>
   <email>lkkforworld@gmail.com</email>
 </author>

 
 <entry>
   <title>ntp 配置</title>
   <link href="/linux/2019/11/30/ntp"/>
   <updated>2019-11-30T00:00:00+08:00</updated>
   <id>/linux/2019/11/30/ntp</id>
   <content type="html">&lt;p&gt;集群情况下，服务器之间的时间同步十分重要，大部分的软件都会设置超时时间，如果服务器的时间和主节点的不一样，可能导致服务异常，ntp的配置是必须的。&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;前提&quot;&gt;前提&lt;/h2&gt;
&lt;p&gt;默认的操作系统Centos7.3-1611 部署软件模式Infrastructure Server&lt;/p&gt;

&lt;p&gt;安装完os时，ntp已经安装好了&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;rpm -aq |grep ntp
rpm -aq |grep libopts
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;已经有ntp ntpupdate libopts&lt;/p&gt;

&lt;p&gt;我们只需要配置ntp接可以了&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pkgs.org&quot;&gt;https://pkgs.org&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;配置&quot;&gt;配置&lt;/h2&gt;

&lt;p&gt;man ntp.conf&lt;/p&gt;

&lt;p&gt;/etc/ntp.conf&lt;/p&gt;

&lt;p&gt;driftfile
includefile 设定包含的配置文件子文件
perfer 表示优先
keys 当进行秘钥方式进行认证的时候需要的文件&lt;/p&gt;

&lt;p&gt;server 127.127.1.0 iburst  # 如果server指定的服务器无法使用， 就使用本机时钟作为ntp服务时间来源&lt;/p&gt;

&lt;p&gt;restrict
权限控制语句&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;restrict your-ip mask [netmask_ip] [parameter]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如：restrict 127.0.0.1&lt;/p&gt;

&lt;p&gt;常用的参数有：&lt;/p&gt;

&lt;p&gt;ignore： 拒绝所有类型的 NTP 联机；&lt;/p&gt;

&lt;p&gt;nomodify： 客户端不能使用 ntpc 与 ntpq 这两支程序来修改服务器的时间参数， 但客户端仍可透过这部主机来进行网络校时的；&lt;/p&gt;

&lt;p&gt;noquery： 客户端不能够使用 ntpq, ntpc 等指令来查询时间服务器，等于不提供 NTP 的网络校时；&lt;/p&gt;

&lt;p&gt;notrap： 不提供 trap 这个远程事件登录的功能。&lt;/p&gt;

&lt;p&gt;notrust： 拒绝没有认证的客户端。&lt;/p&gt;

&lt;p&gt;ntpq -d&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;remote：NTP 主机的 IP 或主机名，左边的符号

如果有『 * 』代表目前正在作用当中的上层 NTP

如果是『 + 』代表也有连上线，而且可作为下一个提供时间更新的候选者。

如果是『 - 』 表示为不合格的ntp服务器

refid：上一层 NTP 主机的地址

st：远程服务器的层级别，0-16,0为最高层，

when：几秒钟前曾经做过时间同步化更新的动作；

poll：下一次更新在几秒钟之后；

reach：已经向上层 NTP 服务器要求更新的次数

delay：网络传输过程当中延迟的时间，单位为 10^(-6) 秒

offset：时间补偿的结果，单位与 10^(-3) 秒

jitter：Linux 系统时间与 BIOS 硬件时间的差异时间， 单位为 10^(-6) 秒。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;note&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;一台机器不能同时是ntp服务器和ntp客户端,两个进程是互斥的,&lt;code class=&quot;highlighter-rouge&quot;&gt;ntpdate必须在ntpd进程关闭状态才可以使用&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&quot;demo&quot;&gt;demo&lt;/h2&gt;

&lt;p&gt;ntp能与互联网上的时钟保持同步,而且本身也是一台NTP服务器,可以为局域网电脑提供校对时间服务&lt;/p&gt;

&lt;p&gt;假定时钟服务器IP地址为：192.168.0.1&lt;/p&gt;

&lt;p&gt;服务器端配置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;1:置/etc/ntp.conf文件内容为：
server 127.127.1.0 minpoll 4
fudge 127.127.1.0 stratum 1
restrict 127.0.0.1
restrict 192.168.0.0 mask 255.255.255.0 nomodify notrap
driftfile /var/lib/ntp/drift

2: /etc/ntp/ntpservers应置空
3: /etc/ntp/step-tickers应配置为 127.127.1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上诉修改完成后，以root用户身份重启ntpd服务:service ntpd restart即可&lt;/p&gt;

&lt;p&gt;客户端配置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;1:置/etc/ntp.conf文件内容为：
server 192.168.0.1
fudge 127.127.1.0 stratum 2
restrict 127.0.0.1
driftfile /var/lib/ntp/drift
restrict 192.168.0.1 mask 255.255.255.255
2. /etc/ntp/ntpservers 文件内容置空
3. /etc/ntp/step-tickers文件内容置为时钟服务器IP地址 192.168.0.1

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上诉修改完成后，以root用户身份重启ntpd服务:service ntpd restart即可
用户可用以下两个常用命令查看ntpd服务状态：
1 ntpq -p
2 ntpstat&lt;/p&gt;

&lt;p&gt;高可用&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;date +&quot;%Y-%m-%d %H:%m:%S&quot;

date -s &quot;2019-11-30 23:11:36&quot;
&lt;/code&gt;&lt;/pre&gt;

</content>
 </entry>
 
 <entry>
   <title>ES操作大全</title>
   <link href="/elasticsearch/2019/09/07/elasticsearch"/>
   <updated>2019-09-07T00:00:00+08:00</updated>
   <id>/elasticsearch/2019/09/07/elasticsearch</id>
   <content type="html">&lt;hr /&gt;

&lt;h3 id=&quot;cat命令&quot;&gt;cat命令&lt;/h3&gt;

&lt;p&gt;首先接触es，了解了基本的架构，加上cat命令操作，加深理解。不管学什么help就是的入门法宝!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;curl http://localhost:9200/cat
=^.^=
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/tasks
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/thread_pool/{thread_pools}
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}
/_cat/nodeattrs
/_cat/repositories
/_cat/snapshots/{repository}
/_cat/templates
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&quot;allocation&quot;&gt;allocation&lt;/h4&gt;

&lt;h4 id=&quot;shards&quot;&gt;shards&lt;/h4&gt;

&lt;h4 id=&quot;master&quot;&gt;master&lt;/h4&gt;

&lt;h4 id=&quot;nodes&quot;&gt;nodes&lt;/h4&gt;

&lt;h4 id=&quot;tasks&quot;&gt;tasks&lt;/h4&gt;

&lt;h4 id=&quot;indices&quot;&gt;indices&lt;/h4&gt;

&lt;h4 id=&quot;segments&quot;&gt;segments&lt;/h4&gt;

&lt;h4 id=&quot;count&quot;&gt;count&lt;/h4&gt;

&lt;h4 id=&quot;recovery&quot;&gt;recovery&lt;/h4&gt;

&lt;h4 id=&quot;health&quot;&gt;health&lt;/h4&gt;

&lt;h4 id=&quot;pending_tasks&quot;&gt;pending_tasks&lt;/h4&gt;

&lt;h4 id=&quot;aliases&quot;&gt;aliases&lt;/h4&gt;

&lt;h4 id=&quot;thread_pool&quot;&gt;thread_pool&lt;/h4&gt;

&lt;h4 id=&quot;plugins&quot;&gt;plugins&lt;/h4&gt;

&lt;h4 id=&quot;fielddata&quot;&gt;fielddata&lt;/h4&gt;

&lt;h4 id=&quot;nodeattrs&quot;&gt;nodeattrs&lt;/h4&gt;

&lt;h4 id=&quot;repositories&quot;&gt;repositories&lt;/h4&gt;

&lt;h4 id=&quot;snapshots&quot;&gt;snapshots&lt;/h4&gt;

&lt;h4 id=&quot;templates&quot;&gt;templates&lt;/h4&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;reference&quot;&gt;reference&lt;/h2&gt;

&lt;p&gt;sql to  dsl&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/360EntSecGroup-Skylar/ElasticHD&quot;&gt;https://github.com/360EntSecGroup-Skylar/ElasticHD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/cch123/elasticsql&quot;&gt;https://github.com/cch123/elasticsql&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Regex 和 Grok</title>
   <link href="/java/2019/05/06/regex_grok"/>
   <updated>2019-05-06T00:00:00+08:00</updated>
   <id>/java/2019/05/06/regex_grok</id>
   <content type="html">&lt;p&gt;在日志解析中，两个很关键的工具Regex,Grok.&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;regex&quot;&gt;Regex&lt;/h2&gt;

&lt;h2&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-1&quot;&gt;#&lt;/h2&gt;

&lt;h3 id=&quot;reference&quot;&gt;reference&lt;/h3&gt;

&lt;p&gt;online test
&lt;a href=&quot;https://txt2re.com&quot;&gt;https://txt2re.com&lt;/a&gt;
&lt;a href=&quot;https://regexr.com/&quot;&gt;https://regexr.com/&lt;/a&gt;
&lt;a href=&quot;https://www.regular-expressions.info/regexmagic.html&quot;&gt;https://www.regular-expressions.info/regexmagic.html&lt;/a&gt;
&lt;a href=&quot;https://tool.lu/regex/&quot;&gt;https://tool.lu/regex/&lt;/a&gt;
&lt;a href=&quot;http://www.kingshang.com/&quot;&gt;http://www.kingshang.com/&lt;/a&gt;
&lt;a href=&quot;https://www.jb51.net/tools/zhengze.htm&quot;&gt;https://www.jb51.net/tools/zhengze.htm&lt;/a&gt;
&lt;a href=&quot;https://regex101.com/&quot;&gt;https://regex101.com/&lt;/a&gt;
&lt;a href=&quot;https://c.runoob.com/front-end/854&quot;&gt;https://c.runoob.com/front-end/854&lt;/a&gt;
&lt;a href=&quot;http://tool.oschina.net/regex/&quot;&gt;http://tool.oschina.net/regex/&lt;/a&gt;
&lt;a href=&quot;http://tool.chinaz.com/regex/&quot;&gt;http://tool.chinaz.com/regex/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/thekrakken/java-grok&quot;&gt;https://github.com/thekrakken/java-grok&lt;/a&gt;
&lt;a href=&quot;https://github.com/aicer/grok&quot;&gt;https://github.com/aicer/grok&lt;/a&gt;
&lt;a href=&quot;https://github.com/ziishaned/learn-regex&quot;&gt;https://github.com/ziishaned/learn-regex&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;grok&quot;&gt;Grok&lt;/h2&gt;

&lt;h2 id=&quot;-2&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-3&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-4&quot;&gt;#&lt;/h2&gt;

</content>
 </entry>
 
 <entry>
   <title>StreamSets 流处理ETL</title>
   <link href="/2019/01/31/streamsets"/>
   <updated>2019-01-31T00:00:00+08:00</updated>
   <id>/2019/01/31/streamsets</id>
   <content type="html">&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h1&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-1&quot;&gt;#&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://streamsets.com/tutorials/&quot;&gt;https://streamsets.com/tutorials/&lt;/a&gt;
&lt;a href=&quot;https://github.com/streamsets/tutorials/blob/master/tutorial-processor/readme.md&quot;&gt;自定义插件&lt;/a&gt;,通过mvn创建项目，依次输入grouyId,artifactId,version,package.&lt;/p&gt;

&lt;h1 id=&quot;-2&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-3&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-4&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-5&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-6&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-7&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-8&quot;&gt;#&lt;/h1&gt;
</content>
 </entry>
 
 <entry>
   <title>Python libs整理</title>
   <link href="/python/2019/01/15/python-libs"/>
   <updated>2019-01-15T00:00:00+08:00</updated>
   <id>/python/2019/01/15/python-libs</id>
   <content type="html">&lt;p&gt;对于日常中Python库的整理&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;json-simplejson&quot;&gt;json simplejson&lt;/h2&gt;

&lt;p&gt;JSON(JavaScript Object Notation)是一种轻量级的数据交换格式&lt;/p&gt;

&lt;p&gt;simplejson比json更新快, simplejson支持的python版本范围更广&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nl&quot;&gt;try:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;simplejson&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImportError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;格式化json格式文件python -m simplejson.tool PATH/json.json&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;在python中使用Json
Import json
.json文件的读入
with open(filePath,'r')as f:
      data = json.load(f)
data是字典类型
可以通过for k,v in data.items()来遍历字典
.json文件的写入
首先存放为.json类型的文件一般是k-v类型的，一般是先打包成字典写入
jsFile = json.dumps(bigramDict)
with open(filepath.json,'w')as f:
    f.write(jsFile)
    f.close()

几个主要函数：dump,dumps,load,loads 带s跟不带s的区别是 带s的是对 字符串的处理，而不带 s的是对文件对像的处理。
函数1dumps(dict):将python字典json化,接收参数为字典类型
函数2sort_keys:设置是否排序字典
函数3dump（）：对文件对象的处理
函数4 loads(str)解析json的字符串
函数5 load()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;pycharts&quot;&gt;pycharts&lt;/h3&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyecharts&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;柱形图
```C
from pyecharts import Bar&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;bar = Bar(“成绩柱形图”, “副标题”)&lt;/p&gt;
&lt;h1 id=&quot;用于添加图表的数据和设置各种配置项&quot;&gt;用于添加图表的数据和设置各种配置项&lt;/h1&gt;
&lt;h1 id=&quot;is_more_utirltrue-可以按右边的下载按钮将图片下载到本地&quot;&gt;is_more_utirl=True 可以按右边的下载按钮将图片下载到本地&lt;/h1&gt;
&lt;p&gt;bur.add(“成绩表”, [“语文”, “数学”, “英语”, “物理”, “化学”, “生物”], [88, 90, 92, 87, 83, 81],)&lt;/p&gt;

&lt;p&gt;bur.add(“成绩表”, [“语文”, “数学”, “英语”, “物理”, “化学”, “生物”], [88, 90, 92, 87, 83, 81],is_more_util=True)
bar.show_config()    # 打印输出图表的所有配置项
bar.render(‘D:\pye\bar.html’)         # 在指定目录下生成一个 bar.html 的文件&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ 饼图
```C
from pyecharts import Pie


attr = [&quot;语文&quot;, &quot;数学&quot;, &quot;英语&quot;, &quot;物理&quot;, &quot;化学&quot;, &quot;生物&quot;]
score = [20, 30, 40, 25, 10, 15]
pie = Pie('图书销量饼图')
pibel_show=True)
pie.render('F:\pye\pie.html')e.add('', attr, score,)

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;圆环图
```C
from pyecharts import Pie&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;attr = [“语文”, “数学”, “英语”, “物理”, “化学”, “生物”]
score = [20, 30, 40, 25, 10, 15]
pie = Pie(‘图书销量圆环图’, title_pos=’center’)
pibel_show=True,
        legend_orient=’vertical’, legend_pos=’left’)
        pie.render(‘F:\pye\pieround.html’)   # 在指定目录下生成文件e.add(‘’, attr, score, radius=[40, 75], label_text_color=None,)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ 3D散图
```C
from pyecharts import Scatter3D
from pyecharts import Page
import random

plmap=True, visual_range_color=range_color)
page.add(scatter3D)
page.render('D:\pye\scatter.html')    # 在指定目录下生成文件age = page()
data = [[random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)] for _ in range(80)]
range_color = ['#313695', '#4575b4', '#74add1', '#abd9e9', '#e0f3f8', '#ffffbf',
               '#fee090', '#fdae61', '#f46d43', '#d73027', '#a50026']
               scatter3d = scatter3d(&quot;3d 散点图示例&quot;, width=1200, height=600)
               scatter3d.add(&quot;&quot;, data,)

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;3D折线图
```C
from pyecharts import Line3D&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;dlmap=True)
Line3D.render(‘F:\pye\3D折线图.html’)    # 在指定目录下生成文件ata = [[1, 2, 3, 4], [1, 2, 3, 4], [0, 4, 8, 16]]
line3d = line3d(“3d 折线图示例”, width=1200, height=600)
line3d.add(“”, data,)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ 仪表盘
```C
from pyecharts import Gauge

gauge = Gauge('项目完成进度')
gauge.add('进度表', '完成率', 88.88)
gauge.render('F:\pye\gauge.html')    # 在指定目录下生成文件

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;漏斗图
```C
from pyecharts import Funnel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;attr = [‘认知’, ‘了解’, ‘认可’, ‘考虑’, ‘意向’, ‘购买’]
value = [120, 100, 80, 60, 40, 20]
funnel = Funnel(‘客户购买分析图’)
fubel_show=True, label_pos=’inside’, label_text_color=’#fff’)
funnel.render(‘F:\pye\funel.html’)    # 在指定目录下生成文件nnel.add(‘买车’, attr, value,)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ 地图
```C
from pyecharts import Geo

decewise=True, visual_split_number=6)
geo.render('F:\pye\geo.html')    # 在指定目录下生成文件lmap=True,ata = [
    (&quot;上海&quot;, 25), (&quot;北京&quot;, 36), (&quot;武汉&quot;, 23), (&quot;舟山&quot;, 12), (&quot;齐齐哈尔&quot;, 14), (&quot;盐城&quot;, 15),
        (&quot;赤峰&quot;, 16), (&quot;青岛&quot;, 18), (&quot;乳山&quot;, 18), (&quot;金昌&quot;, 19), (&quot;泉州&quot;, 21), (&quot;莱西&quot;, 21),
            (&quot;日照&quot;, 21), (&quot;胶南&quot;, 22), (&quot;南通&quot;, 23), (&quot;拉萨&quot;, 24), (&quot;云浮&quot;, 24), (&quot;梅州&quot;, 25)
]
geo = geo('主要城市空气质量', 'pm2.5', title_color='#fff', title_pos='center',
          width=1200, height=600, background_color='#404a59')
attr, value = geo.cast(data)
geo.add('', attr, value, visual_range=[0, 200], visual_text_color='#fff', symbol_size=15,
       )

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;词云图
```C
from pyecharts import WordCloud&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;language = [‘Python’, ‘C++’, ‘C’, ‘Java’, ‘C#’, ‘PHP’, ‘R’, ‘JavaScript’, ‘Go’, ‘Assembly’]
rank = [100, 98.4, 98.2, 97.5, 89.8, 85.4, 83.3, 82.8, 76.7, 74.5]
wordcloud = WordCloud(width=1500, height=700)
wordcloud.add(‘’, language, rank, word_size_range=[20, 100])
wordcloud.render(‘F:\pye\wc.html’)    # 在指定目录下生成文件&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+ 水球图
```C
from pyecharts import Liquid

liquid = Liquid(&quot;水球图&quot;)
liquid.add(&quot;Liquid&quot;, [0.8])
liquid.show_config()
liquid.render('F:\pye\sq.html')    # 在指定目录下生成文件

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;http://pyecharts.org&quot;&gt;http://pyecharts.org&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Java libs整理</title>
   <link href="/java/2019/01/15/java-libs"/>
   <updated>2019-01-15T00:00:00+08:00</updated>
   <id>/java/2019/01/15/java-libs</id>
   <content type="html">&lt;p&gt;对于使用中的Java libs整理&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;fastjson&quot;&gt;fastjson&lt;/h2&gt;

&lt;p&gt;maven:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt;
     &amp;lt;artifactId&amp;gt;fastjson&amp;lt;/artifactId&amp;gt;
     &amp;lt;version&amp;gt;1.2.54&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/alibaba/fastjson&quot;&gt;https://github.com/alibaba/fastjson&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kafka命令大全</title>
   <link href="/kafka/2019/01/03/kafka-cmd"/>
   <updated>2019-01-03T00:00:00+08:00</updated>
   <id>/kafka/2019/01/03/kafka-cmd</id>
   <content type="html">&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;单节点&quot;&gt;单节点&lt;/h2&gt;

&lt;h2&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-1&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-2&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-3&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-4&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-5&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-6&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-7&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-8&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-9&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-10&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-11&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-12&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-13&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-14&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-15&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-16&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-17&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-18&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-19&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-20&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-21&quot;&gt;#&lt;/h2&gt;

&lt;h2 id=&quot;分布式集群&quot;&gt;分布式集群&lt;/h2&gt;

&lt;p&gt;启动zk,kakfa集群,三个节点&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;netstat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntlp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9092&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;netstat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ntlp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2181&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;验证是否启动成功&lt;/p&gt;

&lt;h3 id=&quot;创建topic&quot;&gt;创建topic&lt;/h3&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#$KAFKA_HOME/bin/kafka-topics.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 3 --partitions 6 --topic test
#$KAFKA_HOME/bin/kafka-topics.sh --describe  --zookeeper master:2181,slave1:2181,slave2:2181  --topic test
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;Topic:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;PartitionCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;ReplicationFactor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Configs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Leader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Isr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Leader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Isr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Leader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Isr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Leader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Isr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Leader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Isr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;Topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Leader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Replicas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Isr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Partition:&lt;/p&gt;

&lt;p&gt;Leader:&lt;/p&gt;

&lt;p&gt;Replicas:&lt;/p&gt;

&lt;p&gt;Isr:&lt;/p&gt;

&lt;p&gt;###得到topic的offset&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;/opt/nsfocus/espc/deps/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic topic_name
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;动态增加分区&quot;&gt;动态增加分区&lt;/h3&gt;

&lt;p&gt;Kafka提供了kafka-reassign-partitions.sh这个脚本，可以动态扩容,运行时需要指定一个json文件:&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;version&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;partitions&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;topic&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;partition&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;replicas&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;topic&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;partition&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;replicas&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;topic&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;partition&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;replicas&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},.....&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;生成这个文件，对于所有的topic，也可以自己指定,首先列出当前的的 topic&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KAFKA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafka&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zookeeper&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2181&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KAFKA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafka&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zookeeper&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;localhost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2181&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topics&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;除了&lt;code class=&quot;highlighter-rouge&quot;&gt;__consumer_offsets&lt;/code&gt;,这是一个特殊的topic，记录着所有topic的offset,默认是三个副本，分区通过配置得到和基本的topic的分区是一样的,通过py脚本读取topics的内容，就可以生成上面的json文件&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;note&lt;/code&gt;:Kafka Producer能否&lt;code class=&quot;highlighter-rouge&quot;&gt;动态感知&lt;/code&gt;Topic分区的变化,当然是可以的啦,经过的时间间隔就是&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;决定的,默认是5分钟 Kafka.2.10-0.10.2.1配置参数&lt;a href=&quot;http://kafka.apache.org/0102/documentation.html#producerconfigs&quot;&gt;http://kafka.apache.org/0102/documentation.html#producerconfigs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.iteblog.com/archives/1618.html&quot;&gt;https://www.iteblog.com/archives/1618.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;动态增加副本&quot;&gt;动态增加副本&lt;/h3&gt;

&lt;h2 id=&quot;-22&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-23&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-24&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-25&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-26&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-27&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-28&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-29&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-30&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-31&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-32&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-33&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-34&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-35&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-36&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-37&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-38&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-39&quot;&gt;#&lt;/h2&gt;
</content>
 </entry>
 
 <entry>
   <title>Greenplum集群搭建</title>
   <link href="/database/2018/12/17/Greenplum"/>
   <updated>2018-12-17T00:00:00+08:00</updated>
   <id>/database/2018/12/17/Greenplum</id>
   <content type="html">&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h1&gt;#&lt;/h1&gt;
&lt;h2 id=&quot;-1&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-2&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-3&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-4&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-5&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-6&quot;&gt;#&lt;/h2&gt;
&lt;h1 id=&quot;-7&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-8&quot;&gt;#&lt;/h1&gt;
&lt;h1 id=&quot;-9&quot;&gt;#&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/tetta/p/6043691.html&quot;&gt;https://www.cnblogs.com/tetta/p/6043691.html&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kylin 参数配置大全</title>
   <link href="/kylin/2018/12/14/kylin-config"/>
   <updated>2018-12-14T00:00:00+08:00</updated>
   <id>/kylin/2018/12/14/kylin-config</id>
   <content type="html">&lt;p&gt;记录Kylin的配置参数，可以好的优化程序，保证稳定性。&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;a href=&quot;http://kylin.apache.org/cn/docs/install/configuration.html#spark-config-override&quot;&gt;http://kylin.apache.org/cn/docs/install/configuration.html#spark-config-override&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Spark 配置参数大全</title>
   <link href="/spark/2018/12/13/spark-config"/>
   <updated>2018-12-13T00:00:00+08:00</updated>
   <id>/spark/2018/12/13/spark-config</id>
   <content type="html">&lt;p&gt;使用Spark过程，对使用的到参数进行收集，便于优化.&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;spark16&quot;&gt;Spark1.6&lt;/h2&gt;
&lt;h2&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-1&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-2&quot;&gt;#&lt;/h2&gt;

&lt;h2 id=&quot;spark2&quot;&gt;Spark2&lt;/h2&gt;
&lt;h2 id=&quot;-3&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-4&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-5&quot;&gt;#&lt;/h2&gt;
</content>
 </entry>
 
 <entry>
   <title>Hive 参数配置大全</title>
   <link href="/hive/2018/12/13/hive-config"/>
   <updated>2018-12-13T00:00:00+08:00</updated>
   <id>/hive/2018/12/13/hive-config</id>
   <content type="html">&lt;p&gt;使用Hive的过程，收集相互配置参数，便于优化&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;hive1&quot;&gt;hive1&lt;/h2&gt;

&lt;h3 id=&quot;hive-sitexml&quot;&gt;hive-site.xml&lt;/h3&gt;

&lt;p&gt;hive.exec.mode.local.auto
决定 Hive 是否应该自动地根据输入文件大小，在本地运行（在GateWay运行）
true&lt;/p&gt;

&lt;p&gt;hive.exec.mode.local.auto.inputbytes.max
如果 hive.exec.mode.local.auto 为 true，当输入文件大小小于此阈值时可以自动在本地模式运行，默认是 128兆。
134217728L&lt;/p&gt;

&lt;p&gt;hive.exec.mode.local.auto.tasks.max
如果 hive.exec.mode.local.auto 为 true，当 Hive Tasks（Hadoop Jobs）小于此阈值时，可以自动在本地模式运行。
4&lt;/p&gt;

&lt;p&gt;hive.auto.convert.join
是否根据输入小表的大小，自动将 Reduce 端的 Common Join 转化为 Map Join，从而加快大表关联小表的 Join 速度。
false&lt;/p&gt;

&lt;p&gt;hive.mapred.local.mem
Mapper/Reducer 在本地模式的最大内存量，以字节为单位，0为不限制。
0&lt;/p&gt;

&lt;p&gt;mapred.reduce.tasks
所提交 Job 的 reduer 的个数，使用 Hadoop Client 的配置。
默认是-1，表示Job执行的个数交由Hive来分配
-1&lt;/p&gt;

&lt;p&gt;hive.exec.scratchdir
HDFS路径，用于存储不同 map/reduce 阶段的执行计划和这些阶段的中间输出结果。
/tmp/&lt;user.name&gt;/hive&lt;/user.name&gt;&lt;/p&gt;

&lt;p&gt;hive.metastore.warehouse.dir
Hive 默认的数据文件存储路径，通常为 HDFS 可写的路径。
“&lt;/p&gt;

&lt;p&gt;hive.groupby.skewindata
决定 group by 操作是否支持倾斜的数据。
原理是，在Group by中，对一些比较小的分区进行合并
false&lt;/p&gt;

&lt;p&gt;hive.merge.mapfiles
是否开启合并 Map 端小文件，对于 Hadoop 0.20 以前的版本，起一首新的 Map/Reduce Job，对于 0.20 以后的版本，则是起使用 CombineInputFormat 的 MapOnly Job。
true&lt;/p&gt;

&lt;p&gt;hive.merge.mapredfiles
是否开启合并 Map/Reduce 小文件，对于 Hadoop 0.20 以前的版本，起一首新的 Map/Reduce Job，对于 0.20 以后的版本，则是起使用 CombineInputFormat 的 MapOnly Job。
false&lt;/p&gt;

&lt;p&gt;hive.default.fileformat
Hive 默认的输出文件格式，与创建表时所指定的相同，可选项为 ‘TextFile’ 、 ‘SequenceFile’ 或者 ‘RCFile’。
‘TextFile’&lt;/p&gt;

&lt;p&gt;hive.mapred.mode
Map/Redure 模式，如果设置为 strict，将不允许笛卡尔积。
‘nonstrict’&lt;/p&gt;

&lt;p&gt;hive.exec.parallel
是否开启 map/reduce job的并发提交。
默认Map/Reduce job是顺序执行的，默认并发数量是8，可以配置
false&lt;/p&gt;

&lt;p&gt;hive.security.authorization.enabled
Hive 是否开启权限认证。
开启认证后，需要执行授权语句才能对表进行操作，详细请见hive.apache.org
false&lt;/p&gt;

&lt;p&gt;hive.exec.plan
Hive 执行计划的路径，会在程序中自动进行设置
null&lt;/p&gt;

&lt;p&gt;hive.exec.submitviachild
决定 map/reduce Job 是否应该使用各自独立的 JVM 进行提交（Child进程），默认情况下，使用与 HQL compiler 相同的 JVM 进行提交。
false&lt;/p&gt;

&lt;p&gt;hive.exec.script.maxerrsize
通过 TRANSFROM/MAP/REDUCE 所执行的用户脚本所允许的最大的序列化错误数。
100000&lt;/p&gt;

&lt;p&gt;hive.exec.script.allow.partial.consumption
是否允许脚本只处理部分数据，如果设置为 true ，因broken pipe等造成的数据未处理完成将视为正常。
false&lt;/p&gt;

&lt;p&gt;hive.exec.compress.output
决定查询中最后一个 map/reduce job 的输出是否为压缩格式。
false&lt;/p&gt;

&lt;p&gt;hive.exec.compress.intermediate
决定查询的中间 map/reduce job（中间 stage）的输出是否为压缩格式。
对于只进行Map的数据就没有必要了。压缩可以减少网络IO，提高效率。
false&lt;/p&gt;

&lt;p&gt;hive.intermediate.compression.codec
中间 map/reduce job 的压缩编解码器的类名（一个压缩编解码器可能包含多种压缩类型），该值可能在程序中被自动设置。 LZO&lt;/p&gt;

&lt;p&gt;hive.intermediate.compression.type
中间 map/reduce job 的压缩类型，如 “BLOCK” “RECORD”。&lt;/p&gt;

&lt;p&gt;hive.exec.reducers.bytes.per.reducer
每一个 reducer 的平均负载字节数。
改变此参数可以用来影响hive的启动的Reducer的个数，默认每个Reducer处理1G数据
1000000000&lt;/p&gt;

&lt;p&gt;hive.exec.reducers.max
reducer 个数的上限。
999&lt;/p&gt;

&lt;p&gt;hive.exec.pre.hooks
语句层面，整条 HQL 语句在执行前的 hook 类名。
“&lt;/p&gt;

&lt;p&gt;hive.exec.post.hooks
语句层面，整条 HQL 语句在执行完成后的 hook 类名。&lt;/p&gt;

&lt;p&gt;hive.exec.parallel.thread.number
并发提交时的并发线程的个数。 默认8个
8&lt;/p&gt;

&lt;p&gt;hive.mapred.reduce.tasks.speculative.execution
是否开启 reducer 的推测执行，与 mapred.reduce.tasks.speculative.execution 作用相同。
false&lt;/p&gt;

&lt;p&gt;hive.exec.counters.pull.interval
客户端拉取 progress counters 的时间，以毫秒为单位。
1000L&lt;/p&gt;

&lt;p&gt;hive.exec.dynamic.partition
是否打开动态分区。 需要打开
false&lt;/p&gt;

&lt;p&gt;hive.exec.dynamic.partition.mode
打开动态分区后，动态分区的模式，有 strict 和 nonstrict 两个值可选，strict 要求至少包含一个静态分区列，nonstrict 则无此要求。
建议设置成nonstrict，strict情况下，查询表数据要求强制指定分区。
strict&lt;/p&gt;

&lt;p&gt;hive.exec.max.dynamic.partitions
所允许的最大的动态分区的个数。可以手动增加分区。
1000&lt;/p&gt;

&lt;p&gt;hive.exec.max.dynamic.partitions.pernode
单个 reduce 结点所允许的最大的动态分区的个数。
100&lt;/p&gt;

&lt;p&gt;hive.exec.default.partition.name
默认的动态分区的名称，当动态分区列为’‘或者null时，使用此名称。’’
‘&lt;strong&gt;HIVE_DEFAULT_PARTITION&lt;/strong&gt;’&lt;/p&gt;

&lt;p&gt;hadoop.bin.path
Hadoop Client 可执行脚本的路径，该路径用于通过单独的 JVM 提交 job，使用 Hadoop Client 的配置。
$HADOOP_HOME/bin/hadoop&lt;/p&gt;

&lt;p&gt;hadoop.config.dir
Hadoop Client 配置文件的路径，使用 Hadoop Client 的配置。
$HADOOP_HOME/conf&lt;/p&gt;

&lt;p&gt;fs.default.name
Namenode 的 URL，使用 Hadoop Client 的配置。
file:///&lt;/p&gt;

&lt;p&gt;map.input.file
Map 的输入文件，使用 Hadoop Client 的配置。
null&lt;/p&gt;

&lt;p&gt;mapred.input.dir
Map 的输入目录，使用 Hadoop Client 的配置。
null&lt;/p&gt;

&lt;p&gt;mapred.input.dir.recursive
输入目录是否可递归嵌套，使用 Hadoop Client 的配置。
false&lt;/p&gt;

&lt;p&gt;mapred.job.tracker
Job Tracker 的 URL，使用 Hadoop Client 的配置，如果这个配置设置为 ‘local’，将使用本地模式。
local&lt;/p&gt;

&lt;p&gt;mapred.job.name
Map/Reduce 的 job 名称，如果没有设置，则使用生成的 job name，使用 Hadoop Client 的配置。
null&lt;/p&gt;

&lt;p&gt;mapred.reduce.tasks.speculative.execution
Map/Reduce 推测执行，使用 Hadoop Client 的配置。
null&lt;/p&gt;

&lt;p&gt;hive.metastore.metadb.dir
Hive 元数据库所在路径。
“&lt;/p&gt;

&lt;p&gt;hive.metastore.uris
Hive 元数据的 URI，多个 thrift://地址，以英文逗号分隔。
“&lt;/p&gt;

&lt;p&gt;hive.metastore.connect.retries
连接到 Thrift 元数据服务的最大重试次数。
3&lt;/p&gt;

&lt;p&gt;javax.jdo.option.ConnectionPassword
JDO 的连接密码。
“&lt;/p&gt;

&lt;p&gt;hive.metastore.ds.connection.url.hook
JDO 连接 URL Hook 的类名，该 Hook 用于获得 JDO 元数据库的连接字符串，为实现了 JDOConnectionURLHook 接口的类。
“&lt;/p&gt;

&lt;p&gt;javax.jdo.option.ConnectionURL
元数据库的连接 URL。
“&lt;/p&gt;

&lt;p&gt;hive.metastore.ds.retry.attempts
当没有 JDO 数据连接错误后，尝试连接后台数据存储的最大次数。
1&lt;/p&gt;

&lt;p&gt;hive.metastore.ds.retry.interval
每次尝试连接后台数据存储的时间间隔，以毫秒为单位。
1000&lt;/p&gt;

&lt;p&gt;hive.metastore.force.reload.conf
是否强制重新加载元数据配置，一但重新加载，该值就会被重置为 false。
false&lt;/p&gt;

&lt;p&gt;hive.metastore.server.min.threads
Thrift 服务线程池的最小线程数。
8&lt;/p&gt;

&lt;p&gt;hive.metastore.server.max.threads
Thrift 服务线程池的最大线程数。
0x7fffffff&lt;/p&gt;

&lt;p&gt;hive.metastore.server.tcp.keepalive
Thrift 服务是否保持 TCP 连接。
true&lt;/p&gt;

&lt;p&gt;hive.metastore.archive.intermediate.original
用于归档压缩的原始中间目录的后缀，这些目录是什么并不重要，只要能够避免冲突即可。
‘_INTERMEDIATE_ORIGINAL’&lt;/p&gt;

&lt;p&gt;hive.metastore.archive.intermediate.archived
用于归档压缩的压缩后的中间目录的后缀，这些目录是什么并不重要，只要能够避免冲突即可。
‘_INTERMEDIATE_ARCHIVED’&lt;/p&gt;

&lt;p&gt;hive.metastore.archive.intermediate.extracted
用于归档压缩的解压后的中间目录的后缀，这些目录是什么并不重要，只要能够避免冲突即可。
‘_INTERMEDIATE_EXTRACTED’&lt;/p&gt;

&lt;p&gt;hive.cli.errors.ignore
是否忽略错误，对于包含多的 SQL 文件，可以忽略错误的行，继续执行下一行。
false&lt;/p&gt;

&lt;p&gt;hive.session.id
当前会话的标识符，格式为“用户名_时间”用于记录在 job conf 中，一般不予以手动设置。
“&lt;/p&gt;

&lt;p&gt;hive.session.silent
当前会话是否在 silent 模式运行。 如果不是 silent 模式，所以 info 级打在日志中的消息，都将以标准错误流的形式输出到控制台。
false&lt;/p&gt;

&lt;p&gt;hive.query.string
当前正在被执行的查询字符串。
“&lt;/p&gt;

&lt;p&gt;hive.query.id
当前正在被执行的查询的ID。
“&lt;/p&gt;

&lt;p&gt;hive.query.planid
当前正在被执行的 map/reduce plan 的 ID。
“&lt;/p&gt;

&lt;p&gt;hive.jobname.length
当前 job name 的最大长度，hive 会根据此长度省略 job name 的中间部分。
50&lt;/p&gt;

&lt;p&gt;hive.jar.path
通过单独的 JVM 提交 job 时，hive_cli.jar 所在的路径
“&lt;/p&gt;

&lt;p&gt;hive.aux.jars.path
各种由用户自定义 UDF 和 SerDe 构成的插件 jar 包所在的路径。
“&lt;/p&gt;

&lt;p&gt;hive.added.files.path
ADD FILE 所增加的文件的路径。
“&lt;/p&gt;

&lt;p&gt;hive.added.jars.path
ADD JAR 所增加的文件的路径。
“&lt;/p&gt;

&lt;p&gt;hive.added.archives.path
ADD ARCHIEVE 所增加的文件的路径。
“&lt;/p&gt;

&lt;p&gt;hive.table.name
当前的 Hive 表的名称，该配置将通过 ScirptOperator 传入到用户脚本中。
“&lt;/p&gt;

&lt;p&gt;hive.partition.name
当前的 Hive 分区的名称，该配置将通过 ScriptOperator 传入到用户脚本中。
“&lt;/p&gt;

&lt;p&gt;hive.script.auto.progress
脚本是否周期性地向 Job Tracker 发送心跳，以避免脚本执行的时间过长，使 Job Tracker 认为脚本已经挂掉了。
false&lt;/p&gt;

&lt;p&gt;hive.script.operator.id.env.var
用于识别 ScriptOperator ID 的环境变量的名称。
‘HIVE_SCRIPT_OPERATOR_ID’&lt;/p&gt;

&lt;p&gt;hive.alias
当前的 Hive 别名，该配置将通过 ScriptOpertaor 传入到用户脚本中。
“&lt;/p&gt;

&lt;p&gt;hive.map.aggr
决定是否可以在 Map 端进行聚合操作
true&lt;/p&gt;

&lt;p&gt;hive.join.emit.interval
Hive Join 操作的发射时间间隔，以毫秒为单位。
1000&lt;/p&gt;

&lt;p&gt;hive.join.cache.size
Hive Join 操作的缓存大小，以字节为单位。
25000&lt;/p&gt;

&lt;p&gt;hive.mapjoin.bucket.cache.size
Hive Map Join 桶的缓存大小，以字节为单位。
100&lt;/p&gt;

&lt;p&gt;hive.mapjoin.size.key
Hive Map Join 每一行键的大小，以字节为单位。
10000&lt;/p&gt;

&lt;p&gt;hive.mapjoin.cache.numrows
Hive Map Join 所缓存的行数。
25000&lt;/p&gt;

&lt;p&gt;hive.groupby.mapaggr.checkinterval
对于 Group By 操作的 Map 聚合的检测时间，以毫秒为单位。
100000&lt;/p&gt;

&lt;p&gt;hive.map.aggr.hash.percentmemory
Hive Map 端聚合的哈稀存储所占用虚拟机的内存比例。
0.5&lt;/p&gt;

&lt;p&gt;hive.map.aggr.hash.min.reduction
Hive Map 端聚合的哈稀存储的最小 reduce 比例。
0.5&lt;/p&gt;

&lt;p&gt;hive.udtf.auto.progress
Hive UDTF 是否周期性地报告心跳，当 UDTF 执行时间较长且不输出行时有用。
false&lt;/p&gt;

&lt;p&gt;hive.fileformat.check
Hive 是否检查输出的文件格式。
true&lt;/p&gt;

&lt;p&gt;hive.querylog.location
Hive 实时查询日志所在的目录，如果该值为空，将不创建实时的查询日志。
‘/tmp/$USER’&lt;/p&gt;

&lt;p&gt;hive.script.serde
Hive 用户脚本的 SerDe。
‘org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe’&lt;/p&gt;

&lt;p&gt;hive.script.recordreader
Hive 用户脚本的 RecordRedaer。
‘org.apache.hadoop.hive.ql.exec.TextRecordReader’&lt;/p&gt;

&lt;p&gt;hive.script.recordwriter
Hive 用户脚本的 RecordWriter。
‘org.apache.hadoop.hive.ql.exec.TextRecordWriter’&lt;/p&gt;

&lt;p&gt;hive.hwi.listen.host
HWI 所绑定的 HOST 或者 IP。
‘0.0.0.0’&lt;/p&gt;

&lt;p&gt;hive.hwi.listen.port
HWI 所监听的 HTTP 端口。
9999&lt;/p&gt;

&lt;p&gt;hive.hwi.war.file
HWI 的 war 文件所在的路径。
$HWI_WAR_FILE&lt;/p&gt;

&lt;p&gt;hive.test.mode
是否以测试模式运行 Hive
false&lt;/p&gt;

&lt;p&gt;hive.test.mode.prefix
Hive 测试模式的前缀。
‘test_’&lt;/p&gt;

&lt;p&gt;hive.test.mode.samplefreq
Hive 测试模式取样的频率，即每秒钟取样的次数。
32&lt;/p&gt;

&lt;p&gt;hive.test.mode.nosamplelist
Hive 测试模式取样的排除列表，以逗号分隔。
“&lt;/p&gt;

&lt;p&gt;hive.merge.size.per.task
每个任务合并后文件的大小，根据此大小确定 reducer 的个数，默认 256 M。
256000000&lt;/p&gt;

&lt;p&gt;hive.merge.smallfiles.avgsize
需要合并的小文件群的平均大小，默认 16 M。
16000000&lt;/p&gt;

&lt;p&gt;hive.optimize.skewjoin
是否优化数据倾斜的 Join，对于倾斜的 Join 会开启新的 Map/Reduce Job 处理。
false&lt;/p&gt;

&lt;p&gt;hive.skewjoin.key
倾斜键数目阈值，超过此值则判定为一个倾斜的 Join 查询。
1000000&lt;/p&gt;

&lt;p&gt;hive.skewjoin.mapjoin.map.tasks
处理数据倾斜的 Map Join 的 Map 数上限。
10000&lt;/p&gt;

&lt;p&gt;hive.skewjoin.mapjoin.min.split
处理数据倾斜的 Map Join 的最小数据切分大小，以字节为单位，默认为32M。
33554432&lt;/p&gt;

&lt;p&gt;mapred.min.split.size
Map Reduce Job 的最小输入切分大小，与 Hadoop Client 使用相同的配置。
1&lt;/p&gt;

&lt;p&gt;hive.mergejob.maponly
是否启用 Map Only 的合并 Job。
true&lt;/p&gt;

&lt;p&gt;hive.heartbeat.interval
Hive Job 的心跳间隔，以毫秒为单位。
1000&lt;/p&gt;

&lt;p&gt;hive.mapjoin.maxsize
Map Join 所处理的最大的行数。超过此行数，Map Join进程会异常退出。
1000000&lt;/p&gt;

&lt;p&gt;hive.hashtable.initialCapacity
Hive 的 Map Join 会将小表 dump 到一个内存的 HashTable 中，该 HashTable 的初始大小由此参数指定。
100000&lt;/p&gt;

&lt;p&gt;hive.hashtable.loadfactor
Hive 的 Map Join 会将小表 dump 到一个内存的 HashTable 中，该 HashTable 的负载因子由此参数指定。
0.75&lt;/p&gt;

&lt;p&gt;hive.mapjoin.followby.gby.localtask.max.memory.usage
MapJoinOperator后面跟随GroupByOperator时，内存的最大使用比例
0.55&lt;/p&gt;

&lt;p&gt;hive.mapjoin.localtask.max.memory.usage
Map Join 的本地任务使用堆内存的最大比例
0.9&lt;/p&gt;

&lt;p&gt;hive.mapjoin.localtask.timeout
Map Join 本地任务超时，淘宝版特有特性
600000&lt;/p&gt;

&lt;p&gt;hive.mapjoin.check.memory.rows
设置每多少行检测一次内存的大小，如果超过 hive.mapjoin.localtask.max.memory.usage 则会异常退出，Map Join 失败。
100000&lt;/p&gt;

&lt;p&gt;hive.debug.localtask
是否调试本地任务，目前该参数没有生效
false&lt;/p&gt;

&lt;p&gt;hive.task.progress
是否开启 counters ，以记录 Job 执行的进度，同时客户端也会拉取进度 counters。
false&lt;/p&gt;

&lt;p&gt;hive.input.format
Hive 的输入 InputFormat。
默认是org.apache.hadoop.hive.ql.io.HiveInputFormat，其他还有org.apache.hadoop.hive.ql.io.CombineHiveInputFormat&lt;/p&gt;

&lt;p&gt;hive.enforce.bucketing
是否启用强制 bucketing。
false&lt;/p&gt;

&lt;p&gt;hive.enforce.sorting
是否启用强制排序。
false&lt;/p&gt;

&lt;p&gt;hive.mapred.partitioner
Hive 的 Partitioner 类。
‘org.apache.hadoop.hive.ql.io.DefaultHivePartitioner’&lt;/p&gt;

&lt;p&gt;hive.exec.script.trust
Hive Script Operator For trust
false&lt;/p&gt;

&lt;p&gt;hive.hadoop.supports.splittable.combineinputformat
是否支持可切分的 CombieInputFormat
false&lt;/p&gt;

&lt;p&gt;hive.optimize.cp
是否优化列剪枝。
true&lt;/p&gt;

&lt;p&gt;hive.optimize.ppd
是否优化谓词下推。
true&lt;/p&gt;

&lt;p&gt;hive.optimize.groupby
是否优化 group by。
true&lt;/p&gt;

&lt;p&gt;hive.optimize.bucketmapjoin
是否优化 bucket map join。
false&lt;/p&gt;

&lt;p&gt;hive.optimize.bucketmapjoin.sortedmerge
是否在优化 bucket map join 时尝试使用强制 sorted merge bucket map join。
false&lt;/p&gt;

&lt;p&gt;hive.optimize.reducededuplication
是否优化 reduce 冗余。
true&lt;/p&gt;

&lt;p&gt;hive.hbase.wal.enabled
是否开启 HBase Storage Handler。
true&lt;/p&gt;

&lt;p&gt;hive.archive.enabled
是否启用 har 文件。
false&lt;/p&gt;

&lt;p&gt;hive.archive.har.parentdir.settable
是否启用 har 文件的父目录可设置。
false&lt;/p&gt;

&lt;p&gt;hive.outerjoin.supports.filters
是否启动外联接支持过滤条件。
true&lt;/p&gt;

&lt;p&gt;hive.fetch.output.serde
对于 Fetch Task 的 SerDe 类
‘org.apache.hadoop.hive.serde2.DelimitedJSONSerDe’&lt;/p&gt;

&lt;p&gt;hive.semantic.analyzer.hook
Hive 语义分析的 Hook，在语义分析阶段的前后被调用，用于分析和修改AST及生成的执行计划，以逗号分隔。
null&lt;/p&gt;

&lt;p&gt;hive.cli.print.header
是否显示查询结果的列名，默认为不显示。
false&lt;/p&gt;

&lt;p&gt;hive.cli.encoding
Hive 默认的命令行字符编码。
‘UTF8’&lt;/p&gt;

&lt;p&gt;hive.log.plan.progress
是否记录执行计划的进度。
true&lt;/p&gt;

&lt;p&gt;hive.pull.progress.counters
是否从 Job Tracker 上拉取 counters，淘宝特有配置项。
true&lt;/p&gt;

&lt;p&gt;hive.job.pre.hooks
每个 Job 提交前执行的 Hooks 列表，以逗号分隔，淘宝特有配置项。
“&lt;/p&gt;

&lt;p&gt;hive.job.post.hooks
每个 Job 完成后执行的 Hooks 列表，以逗号分隔，淘宝特有配置项。
“&lt;/p&gt;

&lt;p&gt;hive.max.progress.counters
Hive 最大的进度 couters 个数，淘宝特有配置项。
100&lt;/p&gt;

&lt;p&gt;hive.exec.script.wrapper
Script Operator 脚本调用的封装，通常为脚本解释程序。例如，可以把该变量值的名称设置为”python”，那么传递到 Script Operator 的脚本将会以”python &amp;lt;script command&amp;gt;“的命令形式进行调用，如果这个值为null或者没有设置，那么该脚本将会直接以”&amp;lt;script command&amp;gt;“的命令形式调用。
null&lt;/p&gt;

&lt;p&gt;hive.check.fatal.errors.interval
客户端通过拉取 counters 检查严重错误的周期，以毫秒为单位，淘宝特有配置项。
5000L&lt;/p&gt;

&lt;h2 id=&quot;hive2&quot;&gt;hive2&lt;/h2&gt;
&lt;h3 id=&quot;hive-sitexml-1&quot;&gt;hive-site.xml&lt;/h3&gt;
</content>
 </entry>
 
 <entry>
   <title>Hbase 参数配置大全</title>
   <link href="/hbase/2018/12/13/hbase-config"/>
   <updated>2018-12-13T00:00:00+08:00</updated>
   <id>/hbase/2018/12/13/hbase-config</id>
   <content type="html">&lt;p&gt;使用Hbase过程中使用的参数，进行收集，便于后续优化&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;hbase1&quot;&gt;Hbase1&lt;/h2&gt;

&lt;h3 id=&quot;hbase-sitexml&quot;&gt;hbase-site.xml&lt;/h3&gt;
&lt;h2&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-1&quot;&gt;#&lt;/h2&gt;

&lt;h3 id=&quot;problem&quot;&gt;problem&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;ERROR:org.apache.hadoop.hbase.PleaseHoldException: Master initializing
 1.ntp
 2.config 必须是域名
 3.防火墙&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hbase2&quot;&gt;Hbase2&lt;/h2&gt;
&lt;h3 id=&quot;hbase-sitexml-1&quot;&gt;hbase-site.xml&lt;/h3&gt;
&lt;h2 id=&quot;-2&quot;&gt;#&lt;/h2&gt;
&lt;h2 id=&quot;-3&quot;&gt;#&lt;/h2&gt;
</content>
 </entry>
 
 <entry>
   <title>Hadoop 配置参数大全</title>
   <link href="/hadoop/2018/12/13/hadoop-config"/>
   <updated>2018-12-13T00:00:00+08:00</updated>
   <id>/hadoop/2018/12/13/hadoop-config</id>
   <content type="html">&lt;p&gt;使用Haddoop过程，收集配置参数，便于优化集群。&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;hadoop27&quot;&gt;Hadoop2.7&lt;/h2&gt;
&lt;h3 id=&quot;hadoop-envsh&quot;&gt;hadoop-env.sh&lt;/h3&gt;

&lt;h3 id=&quot;core-sitexml&quot;&gt;core-site.xml&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/core-default.xml&quot;&gt;https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/core-default.xml&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;hdfs-sitexml&quot;&gt;hdfs-site.xml&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml&quot;&gt;https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;mapred-sitexml&quot;&gt;mapred-site.xml&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://hadoop.apache.org/docs/r2.7.3/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml&quot;&gt;https://hadoop.apache.org/docs/r2.7.3/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;yarn-sitexml&quot;&gt;yarn-site.xml&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://hadoop.apache.org/docs/r2.7.3/hadoop-yarn/hadoop-yarn-common/yarn-default.xml&quot;&gt;https://hadoop.apache.org/docs/r2.7.3/hadoop-yarn/hadoop-yarn-common/yarn-default.xml&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;hadoop3&quot;&gt;Hadoop3&lt;/h2&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://hadoop.apache.org/docs&quot;&gt;https://hadoop.apache.org/docs&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>搭建监控平台</title>
   <link href="/monitor/2018/11/30/monitor"/>
   <updated>2018-11-30T00:00:00+08:00</updated>
   <id>/monitor/2018/11/30/monitor</id>
   <content type="html">&lt;p&gt;对应硬件和软件的基本信息进行监控，并实时观察情况&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;采集信息&quot;&gt;采集信息&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://collectd.org/documentation.shtml&quot;&gt;collectd&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;存储信息&quot;&gt;存储信息&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;influxdb&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;可视化展示&quot;&gt;可视化展示&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;Grafana&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;h3 id=&quot;监控cpu-mem-disk&quot;&gt;监控cpu mem disk&lt;/h3&gt;

&lt;h3 id=&quot;监控java进程&quot;&gt;监控java进程&lt;/h3&gt;

&lt;h2 id=&quot;reference&quot;&gt;reference&lt;/h2&gt;

&lt;p&gt;https://github.com/Kylinlin/performance_monitor&lt;/p&gt;

&lt;p&gt;https://www.slothparadise.com/how-to-install-ganglia-on-centos-7/&lt;/p&gt;

&lt;p&gt;http://crazyadmins.com/tag/ganglia-installation-in-centos/
https://www.tecmint.com/install-configure-ganglia-monitoring-centos-linux/
https://blog.csdn.net/lswnew/article/details/79175539&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>搭建分布式大数据平台</title>
   <link href="/2018/11/18/build-big-data-platfrom"/>
   <updated>2018-11-18T00:00:00+08:00</updated>
   <id>/2018/11/18/build-big-data-platfrom</id>
   <content type="html">&lt;ul&gt;
  &lt;li&gt;Hadoop&lt;/li&gt;
  &lt;li&gt;Hive&lt;/li&gt;
  &lt;li&gt;Spark&lt;/li&gt;
  &lt;li&gt;Zookeeper&lt;/li&gt;
  &lt;li&gt;Kafka&lt;/li&gt;
  &lt;li&gt;Hbase&lt;/li&gt;
  &lt;li&gt;Elasticsearch&lt;/li&gt;
  &lt;li&gt;Flink&lt;/li&gt;
  &lt;li&gt;Kylin&lt;/li&gt;
  &lt;li&gt;Flume&lt;/li&gt;
  &lt;li&gt;Redis&lt;/li&gt;
  &lt;li&gt;Druid&lt;/li&gt;
  &lt;li&gt;OpenTSDB&lt;/li&gt;
  &lt;li&gt;Keepalived&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;基础环境&quot;&gt;基础环境&lt;/h2&gt;

&lt;p&gt;软件包要求:Jdk8 Hadoop-2.7,Spark-2.0,Hive-2.3,Hbase-1.2,Zookeeper-3.4.10&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Linux(CentOS7)
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; master ip1
 slave1 ip2
 slave2 ip3
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;SSH&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;免密码登录&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Java&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下载Linux版本的Java8，并安装配置在/etc/profile中增加&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;hadoop&quot;&gt;Hadoop&lt;/h2&gt;

&lt;p&gt;Hadoop2.7&lt;a href=&quot;https://archive.apache.org/dist/hadoop/common/&quot;&gt;[安装包]&lt;/a&gt;
 解压文件重命名hadoop&lt;/p&gt;

&lt;h3 id=&quot;单个namenode&quot;&gt;单个NameNode&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;配置文件在${HADOOP_HOME}/etc/hadoop目录下&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;hadoop-env.sh
 修改JAVA_HOME的值
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; export JAVA_HOME/opt/big-data/java
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;core-site.xml
 修改或增加fs.defualtFS的value
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;hdfs://master:9000&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;修改或增加hadoop.tmp.dir的value&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;file:///opt/big-data/hadoop/tmp&amp;lt;/value&amp;gt;
     &amp;lt;description&amp;gt;Abasefor other temporary directories.&amp;lt;/description&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;用xmllint来格式化验证&lt;/p&gt;
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;xmllint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;如果想了解更多的配置&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/core-default.xml&quot;&gt;[请点击]&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;hdfs-site.xml
 修改或增加dfs.namenode.data.dir的value
    &lt;property&gt;
     &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
     &lt;value&gt;file:///opt/big-data/hadoop/data/hdfs/namenode&lt;/value&gt;
 &lt;/property&gt;
    &lt;p&gt;修改或增加dfs.datanode.data.dir的value&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.datanode.name.dir&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;file:///opt/big-data/hadoop/data/hdfs/datanode&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;修改或增加dfs.replication的value&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;    #datanode数量，默认3，我们是2台设置2
     &amp;lt;value&amp;gt;2&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用xmllint来格式化验证&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;xmllint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;如果想了解更多的配置&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml&quot;&gt;[请点击]&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;mapred-site.xml
 &lt;code class=&quot;highlighter-rouge&quot;&gt;刚解压之后，是没有这个文件的&lt;/code&gt;,需要把mapred-site.xml.template copy为mapred-site.xml
 修改或增加mapreduce.framework.name的value
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; &amp;lt;property&amp;gt;
　　　　&amp;lt;!-指定Mapreduce运行在yarn上--&amp;gt;
     &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;用xmllint来格式化验证&lt;/p&gt;
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;xmllint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;yarn-site.xml
 修改或增加yarn.resourcemanager.hostname的value
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  &amp;lt;!-- 指定ResourceManager的地址--&amp;gt;
 &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;mip&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;修改或增加hadoop.tmp.dir的value
 修改或增加hadoop.tmp.dir的value&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用xmllint来格式化验证&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;xmllint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yarn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;如果想了解更多的配置&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml&quot;&gt;[请点击]&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;log4j.properties
 修改hadoop.log.dir
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; hadoop.log.dir=/opt/big-data/hadoop/log
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;slaves
 这个文件的写的启动datanode/nodemanager的主机名,如果所有节点都启动
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; master
 slave1
 slave2
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;只在从节点启动&lt;/code&gt;，推荐使用这种，可以减少主节点的负载,我采用的就是这种&lt;/p&gt;
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; slave1
 slave2
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;创建配置的目录
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;namenode&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datanode&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Hadoop环境变量
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HADOOP_CONF_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;ol&gt;
      &lt;li&gt;启动集群&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;scp拷贝文件,&lt;code class=&quot;highlighter-rouge&quot;&gt;保证每个节点的文档Hadoop目录文件结构是一样的&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;一键启动
    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;格式化&lt;/code&gt;
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;hdfs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namenode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;启动hdfs
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;启动yarn
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nsfocus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;espc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yarn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;单步启动
    &lt;ol&gt;
      &lt;li&gt;namenode
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namenode&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;secondnamenode&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;datanode
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datanode&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;resourcemanager
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yarn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resourcemanager&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;nodemanager
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yarn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodemanager&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;mapreduce作业日志服务器
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobhistory&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;daemon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;historyserver&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        &lt;p&gt;了解更详细的命令使用&lt;a href=&quot;&quot;&gt;[链接]&lt;/a&gt;&lt;/p&gt;
        &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;hdfs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;yarn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;进程验证
  cmd:
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;jps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iE&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resource&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;master主机 ssh master  cmd&lt;/p&gt;
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;mi&quot;&gt;27911&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SecondaryNameNode&lt;/span&gt;
  &lt;span class=&quot;mi&quot;&gt;26724&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ResourceManager&lt;/span&gt;
  &lt;span class=&quot;mi&quot;&gt;26536&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NameNode&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;slave1主机 ssh slave1 cmd&lt;/p&gt;
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;mi&quot;&gt;26830&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NodeManager&lt;/span&gt;
  &lt;span class=&quot;mi&quot;&gt;26626&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataNode&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;slave2主机 ssh slave2 cmd&lt;/p&gt;
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;mi&quot;&gt;26831&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NodeManager&lt;/span&gt;
  &lt;span class=&quot;mi&quot;&gt;26621&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataNode&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Web预览&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;master:50070&lt;/li&gt;
  &lt;li&gt;master:8088&lt;/li&gt;
  &lt;li&gt;master:19888&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;测试
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  hdfs dfs -mkdir /wordCountInput
  hdfs dfs -put /opt/big-data/hadoop/README.txt /wordCountInput
  hdfs dfs -ls -R /wordCountInput
  hadoop jar /opt/big-data/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount /wordCountInput/README.txt /wordCountOput
  hdfs dfs -ls -R /wordCountOutput
  hdfs dfs -cat /wordCountOput/part-r-00000
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;关闭集群
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yarn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;big&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sbin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ha高可用&quot;&gt;HA高可用&lt;/h3&gt;

&lt;h4 id=&quot;namenode-ha&quot;&gt;NameNode HA&lt;/h4&gt;
&lt;p&gt;为了实现自动切换，需要借助Zookeeper来协调，必须有一个&lt;code class=&quot;highlighter-rouge&quot;&gt;Zookeeper的集群环境&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;problem:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;手动切换namonde为active&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html&quot;&gt;http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;resourcemanager-ha&quot;&gt;ResourceManager HA&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html&quot;&gt;http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;hive&quot;&gt;Hive&lt;/h2&gt;

&lt;p&gt;Hive2.3&lt;a href=&quot;http://mirror.bit.edu.cn/apache/hive/&quot;&gt;[安装包]&lt;/a&gt;解压文件重命名hive&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hive-env.sh&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  export HIVE_CONF_DIR=/opt/big-data/hive/conf
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;hive-site.xml&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;没有这个文件时，拷贝hive-default.xml.template hive-site.xml,元数据库选择，大部分是Mysql,Postgresql&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Mysql&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionURL&lt;/td&gt;		&lt;td&gt;jdbc:mysql://master:3306/metastore?characterEncoding=UTF-8&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionDriverName&lt;/td&gt;		&lt;td&gt;com.mysql.jdbc.Drive&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionUserName&lt;/td&gt;		&lt;td&gt;user&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionPassword&lt;/td&gt;		&lt;td&gt;password&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;hive.metastore.uris&lt;/td&gt;		&lt;td&gt;thrift://master:9083&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;hive.metastore.warehouse.dir&lt;/td&gt;		&lt;td&gt;/user/hive/warehouse&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;hive.querylog.location&lt;/td&gt;		&lt;td&gt;/opt/log/hive&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&lt;/td&gt;		&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
  &lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;Postgresql&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionURL&lt;/td&gt;		&lt;td&gt;jdbc:mysql://master:5432/metastore?characterEncoding=UTF-8&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionDriverName&lt;/td&gt;		&lt;td&gt;org.postgresql.Driver&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionUserName&lt;/td&gt;		&lt;td&gt;user&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;javax.jdo.option.ConnectionPassword&lt;/td&gt;		&lt;td&gt;password&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;hive.metastore.uris&lt;/td&gt;		&lt;td&gt;thrift://master:9083&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;hive.metastore.warehouse.dir&lt;/td&gt;		&lt;td&gt;/user/hive/warehouse&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;hive.querylog.location&lt;/td&gt;		&lt;td&gt;/opt/log/hive&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;&lt;/td&gt;		&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
  &lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;驱动包&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Mysql&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Postgresql&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;spark&quot;&gt;Spark&lt;/h2&gt;

&lt;p&gt;Spark2.0&lt;a href=&quot;http://spark.apache.org/downloads.html&quot;&gt;[安装包]&lt;/a&gt;
  解压文件重命名spark&lt;/p&gt;
&lt;h3 id=&quot;hive-on-spark&quot;&gt;Hive on Spark&lt;/h3&gt;

&lt;h3 id=&quot;spark-thrift&quot;&gt;Spark Thrift&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;spark提交任务java.nio.channels.ClosedChannelException
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;ERROR client.TransportClient: Failed to send RPC 6159851572252707613 to /0.0.0.0:39986: java.nio.channels.ClosedChannelException
java.nio.channels.ClosedChannelException
&lt;/code&gt;&lt;/pre&gt;
    &lt;p&gt;内存的原因,是从yarn-site.xml中配置计算来的，yarn.scheduler.minimum-allocation-mb  * yarn.nodemanager.vmem-pmem-ratio = 虚拟内存的总量，如果需要的虚拟内存总量超过这个计算所得的数值，就会出发 Killing container.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此处 我的yarn.scheduler.minimum-allocation-mb值没设置，默认为1G，yarn.nodemanager.vmem-pmem-ratio也没设置，默认为2.1,给spark 任务配置更大的内存即可解决问题&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;	&amp;lt;kroperty&amp;gt;
			&amp;lt;name&amp;gt;yarn.scheduler.maximum-allocation-mb&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;9216&amp;lt;/value&amp;gt;
			&amp;lt;discription&amp;gt;每个任务最多可用内存,单位MB,默认8182MB&amp;lt;/discription&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;yarn.scheduler.minimum-allocation-mb&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;4000&amp;lt;/value&amp;gt;
			&amp;lt;discription&amp;gt;每个任务最shao可用内存&amp;lt;/discription&amp;gt;
	&amp;lt;/property&amp;gt;
	&amp;lt;property&amp;gt;
			&amp;lt;name&amp;gt;yarn.nodemanager.vmem-pmem-ratio&amp;lt;/name&amp;gt;
			&amp;lt;value&amp;gt;4.1&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;way-2:通过关闭虚拟内存的检查&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;&amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.vmem-check-enabled&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;zookeeper&quot;&gt;Zookeeper&lt;/h2&gt;

&lt;p&gt;Zookeeper3.4.10&lt;a href=&quot;https://archive.apache.org/dist/zookeeper/&quot;&gt;[安装包]&lt;/a&gt;
  解压文件重命名Zookeeper&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;配置文件
    &lt;ol&gt;
      &lt;li&gt;zoo.cfg
  修改或增加dataDir和logDir
        &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  dataDir=/opt/big-data/zookeeper/data
&lt;/code&gt;&lt;/pre&gt;
        &lt;p&gt;增加下面配置:&lt;/p&gt;
        &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  server.1=master:2888:3888
  server.2=slave1:2888:3888
  server.3=slave2:2888:3888
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
      &lt;li&gt;myid
  这个文件与zoo.cfg配置有关.server.数字与主机名是一一对应的。这个文件的目录在zk的数据目录下/opt/big-data/zookeeper/data
        &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  master:
  cat myid
  1
  slaves1:
  cat myid
  2
  slaves3:
  cat myid
  3
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
      &lt;li&gt;log4j.properties
  修改zookeeper日志输出目录
        &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  zookeeper.log.dir=/opt/big-data/zookeeper/log
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;环境变量
  在/etc/profile添加下面配置，然后source /etc/profile生效
    &lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;  export ZK_HOME=/opt/big-data/zookeeper
  export PATH=$PATH:$ZK_HOME/bin
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;启动ZK集群
  拷贝文件到每个节点对应的目录下，并且&lt;code class=&quot;highlighter-rouge&quot;&gt;修改myid的值&lt;/code&gt;
  在每个节点上执行
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;zkServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;验证状态
  在每个节点上执行
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;zkServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
    &lt;p&gt;会有一个是leader，其他都是follower&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;关闭集群
  在每个节点上执行
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;zkServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;kafka&quot;&gt;Kafka&lt;/h2&gt;

&lt;p&gt;Kafka0.9.0.1&lt;a href=&quot;http://kafka.apache.org/downloads&quot;&gt;[安装包]&lt;/a&gt;
  解压文件重命名kafka&lt;/p&gt;

&lt;h2 id=&quot;hbase&quot;&gt;Hbase&lt;/h2&gt;

&lt;p&gt;Hbase1.2.8&lt;a href=&quot;http://archive.apache.org/dist/hbase/&quot;&gt;[安装包]&lt;/a&gt;
  解压文件重命名hbase&lt;/p&gt;

&lt;h2 id=&quot;elasticsearch&quot;&gt;Elasticsearch&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-sql.html&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-sql.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/blog/an-introduction-to-elasticsearch-sql-with-practical-examples-part-1&quot;&gt;https://www.elastic.co/blog/an-introduction-to-elasticsearch-sql-with-practical-examples-part-1&lt;/a&gt;
jdbc 官网需要会员支持&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/NLPchina/elasticsearch-sql&quot;&gt;https://github.com/NLPchina/elasticsearch-sql&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;离线安装&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugin&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;package&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugin&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;操作过程&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-sql.html&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-sql.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;flink&quot;&gt;Flink&lt;/h2&gt;
&lt;h2 id=&quot;kylin&quot;&gt;Kylin&lt;/h2&gt;
&lt;h2 id=&quot;flume&quot;&gt;Flume&lt;/h2&gt;
&lt;h2 id=&quot;redis&quot;&gt;Redis&lt;/h2&gt;
&lt;h2 id=&quot;druid&quot;&gt;Druid&lt;/h2&gt;
&lt;h2 id=&quot;opentsdb&quot;&gt;OpenTSDB&lt;/h2&gt;
&lt;h2 id=&quot;keepalived&quot;&gt;Keepalived&lt;/h2&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;javax.jdo.JDODataStoreException: Required table missing : “&lt;code class=&quot;highlighter-rouge&quot;&gt;VERSION&lt;/code&gt;” in Catalog “” Schema “”.
 在执行启动hive metastore时报错：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解决方法:初始化一下数据库即可&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt; /hive/bin/schematool -dbType mysql -initSchema
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;Exception in thread “main” MetaException(message:Version information not found in metastore. )
 hive-site.xml
 ```C&lt;/li&gt;
&lt;/ul&gt;
&lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;  ```
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;reference&quot;&gt;reference&lt;/h2&gt;

&lt;p&gt;Apache archive &lt;a href=&quot;http://archive.apache.org/dist/&quot;&gt;http://archive.apache.org/dist/&lt;/a&gt;
持续更新中….&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Linux Crontab 定时执行任务</title>
   <link href="/linux/2018/11/16/Crontab"/>
   <updated>2018-11-16T00:00:00+08:00</updated>
   <id>/linux/2018/11/16/Crontab</id>
   <content type="html">&lt;p&gt;Crontab 添加定时任务&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;crontab-命令&quot;&gt;Crontab 命令&lt;/h2&gt;

&lt;h2 id=&quot;crontab-格式&quot;&gt;Crontab 格式&lt;/h2&gt;

</content>
 </entry>
 
 <entry>
   <title>HDFS数据加密空间-Encryption zone</title>
   <link href="/big-data/2018/11/14/hdfs-encryption"/>
   <updated>2018-11-14T00:00:00+08:00</updated>
   <id>/big-data/2018/11/14/hdfs-encryption</id>
   <content type="html">&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;reference&quot;&gt;reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.2cto.com/kf/201605/509285.html&quot;&gt;https://www.2cto.com/kf/201605/509285.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html&quot;&gt;http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Linux磁盘扩容</title>
   <link href="/2018/11/14/lvm"/>
   <updated>2018-11-14T00:00:00+08:00</updated>
   <id>/2018/11/14/lvm</id>
   <content type="html">&lt;p&gt;当数据量越来越大的时候，磁盘空间需要进一步扩容，来应对的我们的需求。可通过LVM来管理磁盘和动态扩容。&lt;/p&gt;

&lt;p&gt;LVM  Logical Volume Manage (逻辑卷管理),工作原理:&lt;/p&gt;

&lt;p&gt;LVM在每个物理卷头部都维护了一个metadata，每个metadata中都包含了整个VG（volume group：卷组）的信息，包括每个VG的布局配置，PV（physical volume：物理卷）的编号，LV（logical volume：逻辑卷）的编号，以及每个PE（physical extends：物理扩展单元）到LE（logical extends：物理扩展单元）的映射关系。同一个VG中的每个PV头部的信息都是相同的，这样有利于故障时进行数据恢复。&lt;/p&gt;

&lt;p&gt;LVM对上层文件系统提供LV层，隐藏了操作细节。对文件系统而言，对LV的操作与原先对partition的操作没有差别。当对LV进行写入操作的时候，LVM定位相应的LE，通过PV头部的映射表将数据写入到相应的PE上。LVM实现的关LVM最大的特点就是可以对&lt;code class=&quot;highlighter-rouge&quot;&gt;磁盘进行动态管理&lt;/code&gt;。因为逻辑卷的大小是可以动态调整的，而且不会丢失现有的数据。我们如果新增加了硬盘，其也不会改变现有上层的逻辑卷。键在于PE和LE之间建立映射关系，不同的映射规则决定了不同的LVM存储模型。LVM支持多个PV 的stripe和mirror。&lt;/p&gt;

&lt;p&gt;LVM最大的特点就是可以对磁盘进行动态管理，因为逻辑卷的大小是可以动态调整的，而且不会丢失现有的数据，如果我们增加了硬盘也不会改变现有的上层逻辑卷。&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;lvm-优缺点&quot;&gt;LVM 优缺点&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;优点&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;文件系统可以跨多个磁盘，因此文件系统大小不会受物理磁盘的限制。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以在系统运行的状态下动态的扩展文件系统的大小。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以增加新的磁盘到LVM的存储池中。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以以镜像的方式冗余重要的数据到多个物理磁盘。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以方便的导出整个卷组到另外一台机器。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;缺点&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;在从卷组中移除一个磁盘的时候必须使用&lt;code class=&quot;highlighter-rouge&quot;&gt;reducevg&lt;/code&gt;命令（这个命令要求root权限，并且不允许在快照卷组中使用）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;当卷组中的一个磁盘损坏时，整个卷组都会受到影响。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因为加入了额外的操作，存贮性能受到影响。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;术语&quot;&gt;术语&lt;/h2&gt;
&lt;p&gt;PV(physical volum)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>tutorialspoint 一个好用的学习网站</title>
   <link href="/2018/11/13/tutorialspoint"/>
   <updated>2018-11-13T00:00:00+08:00</updated>
   <id>/2018/11/13/tutorialspoint</id>
   <content type="html">&lt;p&gt;tutorialspoint 是印度人开发的一个网站，整理了大量的学习资料,方便查询&lt;/p&gt;

&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;reference&quot;&gt;reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.tutorialspoint.com&quot;&gt;https://www.tutorialspoint.com&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Keepalive 高可用</title>
   <link href="/ha/2018/11/08/keepalived"/>
   <updated>2018-11-08T00:00:00+08:00</updated>
   <id>/ha/2018/11/08/keepalived</id>
   <content type="html">&lt;hr /&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;安装&quot;&gt;安装&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Centos6
 rpm 进行安装,下载&lt;a href=&quot;ihttps://pkgs.org/&quot;&gt;Keepalived&lt;/a&gt;
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;cp&quot;&gt;# rpm -ivh keepalived-1.2.13-5.el6_6.x86_64.rpm
&lt;/span&gt;  &lt;span class=&quot;nl&quot;&gt;warning:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;el6_6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x86_64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rpm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Header&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RSA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SHA1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Signature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ID&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c105b9de&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NOKEY&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Preparing&lt;/span&gt;                &lt;span class=&quot;err&quot;&gt;###########################################&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;             &lt;span class=&quot;err&quot;&gt;###########################################&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Centos7
 源码安装:下载&lt;a href=&quot;http://www.keepalived.org/index.html&quot;&gt;tar.gz&lt;/a&gt;
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;cp&quot;&gt;#tar xf keepalived-2.0.8.tar.gz
&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;#mv keepalived-2.0.8 keepalived
&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;#cd keepalived
&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;#./configure --prefix=/usr/local/keepalived
&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;#make &amp;amp;&amp;amp; make install
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;配置
    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sysconfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sysconfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keeplalived&lt;/span&gt;
 &lt;span class=&quot;cp&quot;&gt;# start keepalived
&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;systemd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;systemctl&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepalived&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Keepalived Configuration Manual Page&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.keepalived.org/manpage.html&quot;&gt;http://www.keepalived.org/manpage.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.keepalived.org/index.html&quot;&gt;http://www.keepalived.org/index.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/clsn/p/8052649.html#auto_id_17&quot;&gt;https://www.cnblogs.com/clsn/p/8052649.html#auto_id_17&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
